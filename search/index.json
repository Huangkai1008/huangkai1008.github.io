[{"content":"数据模型与查询语言 数据模型 多数应用使用层层叠加的数据模型来构建，例如：\n 作为应用开发人员，观察现实世界（其中包括人员、组织、货物、行为、资金流向、传感器等），并通过对象或数据结构，以及操控那些数据结构的 API 来进行建模。这些结构通常是特定于该应用程序。 当需要存储那些数据结构时，可以利用通用数据模型来表示它们，如 JSON 或 XML 文档、关系数据库中的表或图模型。 数据库软件的工程师决定如何以内存、磁盘或网络上的字节来表示 JSON / XML/ 关系 / 图数据。数据表示需要支持多种方式的查询、搜索、操作和处理。 在更低的层次上，硬件工程师则需要考虑用电流、光脉冲、磁场或者其他东西来表示字节的方法。  复杂的应用程序可能会有更多的中间层，但是基本思想相同：每层都通过提供一个简洁的数据模型来隐藏下层的复杂性。\n关系模型与文档模型 数据模型的演变  层次模型（hieranchical model）：将所有数据表示为嵌套在记录中的记录树，和 JSON 结构有一些类似。在20世纪70年代 IBM 公司的信息管理系统（IMS）中使用。 网状模型（network model）：网状模型由一个称为数据系统语言会议（CODASYL）的委员会进行了标准化，并被数个不同的数据库厂商实现。它也被称为 CODASYL 模型，CODASYL 模型是层次模型的推广。 关系模型（relational model）：数据被组织成 关系，其中每个关系是 元组的无序集合。SQL 基于关系模型，其中 SQL 中的表对应关系模型中的关系，行对应关系模型中的元组。 文档模型（document-oriented model） 图模型（graphical model） 图模型（graphical model）  对象-关系不匹配 应用层的数据模型和 SQL 数据模型中存在差异，需要一个转换层，模型之间的不连贯有时被称为 阻抗不匹配（impedance mismatch） ，对象-关系映射（ORM，object-relational mapping） 框架可以减少转换层的工作量，但是无法完全隐藏两个模型之间的差异。一般来说，文档模型可以减少应用程序代码和存储层之间的阻抗不匹配，具有更好的 局部性（locality）\n对于一个像简历这样自包含文档的数据结构而言，JSON 表示是非常合适的。\n例：用 JSON 文档表示一个 LinkedIn 简介\n{ \u0026#34;user_id\u0026#34;: 251, \u0026#34;first_name\u0026#34;: \u0026#34;Bill\u0026#34;, \u0026#34;last_name\u0026#34;: \u0026#34;Gates\u0026#34;, \u0026#34;summary\u0026#34;: \u0026#34;Co-chair of the Bill \u0026amp; Melinda Gates... Active blogger.\u0026#34;, \u0026#34;region_id\u0026#34;: \u0026#34;us:91\u0026#34;, \u0026#34;industry_id\u0026#34;: 131, \u0026#34;photo_url\u0026#34;: \u0026#34;/p/7/000/253/05b/308dd6e.jpg\u0026#34;, \u0026#34;positions\u0026#34;: [ { \u0026#34;job_title\u0026#34;: \u0026#34;Co-chair\u0026#34;, \u0026#34;organization\u0026#34;: \u0026#34;Bill \u0026amp; Melinda Gates Foundation\u0026#34; }, { \u0026#34;job_title\u0026#34;: \u0026#34;Co-founder, Chairman\u0026#34;, \u0026#34;organization\u0026#34;: \u0026#34;Microsoft\u0026#34; } ], \u0026#34;education\u0026#34;: [ { \u0026#34;school_name\u0026#34;: \u0026#34;Harvard University\u0026#34;, \u0026#34;start\u0026#34;: 1973, \u0026#34;end\u0026#34;: 1975 }, { \u0026#34;school_name\u0026#34;: \u0026#34;Lakeside School, Seattle\u0026#34;, \u0026#34;start\u0026#34;: null, \u0026#34;end\u0026#34;: null } ], \u0026#34;contact_info\u0026#34;: { \u0026#34;blog\u0026#34;: \u0026#34;http://thegatesnotes.com\u0026#34;, \u0026#34;twitter\u0026#34;: \u0026#34;http://twitter.com/BillGates\u0026#34; } } 多对一与多对多的关系 对于关系数据库，由于支持联结操作，可以很方便地通过 ID 来引用其他表中的行。而在文档数据库中，一对多的树结构不需要联结，对于联结的支持通常也很弱。\n在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同：在这两种情况下，相关项目都被一个唯一的标识符引用，这个标识符在关系模型中被称为 外键，在文档模型中称为 文档引用。\n关系数据库与文档数据库的对比 适合的场景 如果应用数据具有类似文档的结构（即一对多关系树，通常一次性加载整个树），这种场景下适合使用文档模型。\n对于使用多对多关系或者高度关联的数据，关系模型可以胜任此场景，但是图模型是最适合的。\n模式灵活性 文档数据库有时称为 无模式（schemaless） ，更精确的术语应该是 读时模式（schema-on-read，数据的结构是隐式的，只有在读取时才解释），与 写时模式（schema-on-write，关系数据库的一种传统方法，模式是显式的，并且数据库确保数据写入时都必需遵循） 相对应。\n查询的数据局部性 如果应用程序需要频繁访问整个文档，那么存储局部性会带来性能优势。如果将数据分割到多个表中，则需要进行多次索引查找才能将其全部检索出来，这可能需要更多的磁盘查找并花费更多的时间。\n局部性仅仅适用于同时需要文档绝大部分内容的情况。\n图数据模型 图由两种对象组成：顶点（vertex，也称为节点（node）/ 实体（entity）） 和 边（edge，也称为关系(relationship) / 弧（arc））。\n很多数据可以建模为图，图很适合用来处理大量多对多关系的场景，典型的例子包括：\n  社交网络\n顶点是人，边指示哪些人彼此认识。\n  web 图\n顶点是网页，边表示与其他页面的 HTML 链接。\n  公路或铁路网\n顶点是交叉路口，边表示它们之间的公路或铁路线路\n  可以将很多著名的算法运用到这些图上。例如，汽车导航系统搜索道路网络中两点之间的最短路径，PageRank 可以计算 web 图上网页的流行度，从而确定搜索排名。\n另外·，图并不局限于以上提到的同构数据，图也提供了单个数据存储区中保存完全不同类型对象的一致性方式。\n属性图 在 **属性图模型（property graph）**中，\n每个顶点包括：\n 唯一的标识符 出边的集合（outgoing edges） 入边的集合（ingoing edges） 属性的集合（键值对）  每个边包括：\n 唯一的标识符 边的起点（尾部顶点，tail vertex） 边的终点（头部顶点，head vertex） 描述两个顶点间关系类型的标签 属性的集合（键值对）  使用属性图构建的数据库有 Neo4j、Titan、InfiniteGraph 等。\n三元存储模型 在 三元存储（triple-store） 中，所有信息都以非常简单的三部分形式存储：主语、谓语、宾语。\n三元组的主语相当于图中的一个顶点。而宾语包括以下两种：\n 原始数据类型中的值，例如字符串和数字。在这种情况下，三元组的谓语和宾语相当于主语顶点上的属性的键和值。 图中的另一个顶点。此时，谓语是图中的边，主语是尾部顶点，宾语是头部顶点。  混合持久化 不同的应用程序有不同的需求，某个用例的最佳技术选择未必适合另一个用例。因此，在可预见的将来，关系数据库可能会继续与各种非关系数据库一起使用 - 这种思路有时也被称为 混合持久化（polyglot persistence）。\n数据查询语言 命令式与声明式 命令式语言告诉计算机以特定顺序执行某些操作；\n声明式查询语言只需指定所需的数据模式，结果需满足什么条件，以及如何转换数据（例如，排序、分组和聚合），而不需指明如何实现这一目标。数据库系统的查询优化器会决定采用哪些索引和联结，以及用何种顺序来执行查询的各个语句。\n声明式查询语言比命令式 API 更加简洁易用，更重要的是，它还隐藏了数据库引擎的实现细节，这使得数据库系统可以在无需对查询做任何更改的情况下提高性能。\n声明式语言对于并行执行更加友好。\n例如查询动物物种列表中的鲨鱼这个场景：\njavascript 的写法是这样的：\nfunction getSharks() { var sharks = []; for (var i = 0; i \u0026lt; animals.length; i++) { if (animals[i].family === \u0026#34;Sharks\u0026#34;) { sharks.push(animals[i]); } } return sharks; } 关系代数的写法是这样的： $$ sharks = σ_{family = \u0026ldquo;sharks\u0026rdquo;}(animals) $$ SQL 的写法是这样的：\nSELECT*FROManimalsWHEREfamily=\u0026#39;sharks\u0026#39;;MapReduce 查询  MapReduce 是一种编程模型，用于在多台机器上批量处理大规模的数据。\n MapReduce 既不是一个声明式的查询语言，也不是一个完全命令式的查询 API。\n","date":"2022-02-19T11:13:32+08:00","permalink":"https://huangkai1008.github.io/p/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80/","title":"数据模型与查询语言"},{"content":"可靠、可扩展与可维护的应用系统 数据密集型应用  数据密集型应用（Data-Intensive Application) 的制约因素通常是“数据”，包括数据的规模、数据的复杂度或者数据产生与变化的速率；计算密集型应用（Compute-Intensive） 的瓶颈通常在CPU。\n 数据系统 数据密集型应用通常也是基于标准模块构建而成，每个模块负责单一的常用功能，这些模块都属于 数据处理系统（data systems）：\n 数据库（databases） ：存储数据，使得应用可以再次访问 高速缓存（caches) ：缓存复杂或操作代价昂贵的结果，以加快下一次访问 索引（search indexes） ： 用户可以按关键字搜索数据并支持各种过滤方式 流处理（stream processing） ：持续发送消息到另一个进程，处理采用异步的方式 批处理（batch processing） ：定期处理大量的累积数据  数据系统之间的界限正在变得模糊，例如 Redis 既可以用于数据存储也可以用于消息队列，Kafka 作为消息队列也具备持久化存储保证。\n其次，越来越多的应用程序需求广泛，单个工具不足以满足所有的数据处理和存储需求。因此需要将任务分解，每个组件负责高效完成其中一部分，多个组件依靠应用层代码驱动有机衔接起来。\n下图1-1展示了一种数据系统架构：\n 图1-1 一种数据系统架构 \n目标  可靠性（Reliability） ： 当出现意外情况如硬件、软件故障、人为失误等，系统应可以继续正常运转并确保功能的正确性 可扩展性（Scalability）：也被称为可伸缩性，随着规模的增长，例如数据量、流量或复杂性，系统应以合理的方式来匹配这种增长 可维护性（Maintainability）：许多新的人员在不同的生命周期参与到系统开发或者运维，系统都可以合理工作（系统会保持现有行为，并适应新的应用场景）  可靠性 可靠的定义  应用程序执行用户所期望的功能 可以容忍用户出现不正确的软件使用方法 性能可以应对典型场景、合理的负载压力和数据量 系统可以防止任何未经授权的访问和滥用  可靠性大致意味着：即使发生了某些错误，系统仍可以继续正常工作。\n故障与失效 可能出错的事情称为 错误（faults） 或故障，系统可以应对错误的特性称为 容错（tolerant） 或 弹性（resilient） 。\n故障与 失效（failure） 不完全一致。故障通常被定义为组件偏离正常规格，失效意味着系统作为一个整体停止，无法向用户提供所需的服务。故障不太可能降低到零，因此通常设计容错机制避免从故障引发系统失效。比较重要的事情是如何在不可靠组件基础上构建可靠性系统。\n硬件故障（hardware faults） 在机器足够多的情况，硬件故障的情况迟早会发生。\n对于硬件故障的场景，一般采用两种思路去减少系统故障率：\n  为硬件添加冗余，可以减少单台机器完全失效的概率：\n磁盘配置RAID，服务器配备双电源，热插拔CPU，数据中心添加备用电源、发电机等\n  增加软件容错的方式\n  软件故障  接受特定的错误输入，便导致所有应用服务器实例崩溃的 BUG 失控进程会用尽一些共享资源，包括 CPU 时间、内存、磁盘空间或网络带宽 系统依赖的服务变慢，没有响应，或者开始返回错误的响应 级联故障，一个组件中的小故障触发另一个组件中的故障，进而触发更多的故障  人为失误 应对的方法有：\n 以最小化出错的方式设计系统，例如精心设计的抽象层、API 和管理后台 分离出最容易出错的地方、容易引发故障的接口，提供一个功能齐全但非生产用的沙箱环境 充分测试，包括单元测试到全系统集成测试以及手动测试 提供快速的回滚恢复机制 设置详细而清晰的监控子系统，包括性能指标和错误率 推动管理流程并加以培训  可扩展性 可扩展性 是用来描述系统应对负载增长能力的术语。\n负载的定义 负载可以用一些称为 负载参数（load parameters） 的数字来描述。参数的最佳选择取决于系统架构，它可能是 Web 服务器的每秒请求处理次数、数据库中写入的比例、同时活跃的用户数量、缓存命中率等。有时平均值很重要，有时系统瓶颈来自于少数峰值。\n性能的定义 在系统负载变化的情况下，一般需要从两个方面考虑性能：\n 负载增加，但系统资源（CPU、内存、网络带宽等）保持不变，系统性能会发生什么变化 负载增加，如果需要保持性能不变，需要增加多少系统资源  对于系统性能的定义，不同类型的系统考虑的角度有很大差异：\n对于Hadoop这样的批处理系统，我们通常关心 吞吐量（throughput），即每秒可处理的记录条数，或者在特定规模数据集上运行作业的总时间 ；而在线系统通常更看重服务的 响应时间（response time），即客户端从发送请求到接收响应之前的间隔。\n 延迟（latency） 和 响应时间（response time） 的不同：\n响应时间通常指的是客户端看到的，除了处理请求时间（服务时间，service time） 外，还包括网络延迟和排队延迟；延迟是指某个请求等待处理的持续时长，在此期间它处于 休眠（latent） 状态，并等待服务返回结果。\n 响应时间的性能指标 即使不断重复发送相同的请求，每次得到的响应时间也都会有所不同，所以需要将响应时间视为一个可以测量的数值 分布（distribution），而不是单个数值。\n相比 算数平均值（arithmetic mean） 而言，用百分位点（percentiles） 这个指标去得到 典型（typical） 的响应时间更好。\n例如第 95、99 和 99.9 百分位点（缩写为 p95，p99 和 p999）。它们意味着 95%、99% 或 99.9% 的请求响应时间要比该阈值快，例如：如果第 95 百分位点响应时间是 1.5 秒，则意味着 100 个请求中的 95 个响应时间快于 1.5 秒，而 100 个请求中的 5 个响应时间超过 1.5 秒。\n采用较高的响应时间百分位数（tail latencies，尾部效应或长尾效应）很重要。百分位点通常用于 服务级别目标（SLO, service level objectives） 和 服务级别协议（SLA, service level agreements），即定义服务预期性能和可用性的合同。 SLA 可能会声明，如果服务响应时间的中位数小于 200 毫秒，且 99.9 百分位点低于 1 秒，则认为服务工作正常（如果响应时间更长，就认为服务不达标）。这些指标为客户设定了期望值，并允许客户在 SLA 未达标的情况下要求退款。\n排队延迟（queueing delay） 通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其 CPU 核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为 头部阻塞（head-of-line blocking） 。当一个请求需要多个后端请求时，单个后端慢请求就会拖慢整个终端用户的请求\n如何应对负载增加 通常来说，针对特定级别负载而设计的架构不太可能应付超出预设目标10倍的实际负载，因此当目标服务处于快速增长阶段，需要认真考虑每增加一个数量级的负载，架构如何重新设计。\n垂直扩展和水平扩展  垂直扩展（scaling up，vertical scaling）：升级到更强大的机器 水平扩展（scaling out，horizental scaling） ：将负载分布到多个更小的机器，跨多台机器分配负载也被称为 无共享（shared-nothing） 架构。  现实世界中的优秀架构需要将这两种方法务实地结合。\n自动扩展与手动扩展 有些系统是 弹性（elastic） 的，这意味着可以在检测到负载增加时自动增加计算资源，而其他系统则是手动扩展 （人工分析容量并决定向系统添加更多的机器）。如果负载极难预测，则弹性系统可能很有用，但手动扩展系统更简单，并且意外操作可能会更少。\n分布式扩展 跨多台机器部署 无状态服务（stateless services） 非常简单，但将带状态的数据系统从单节点变为分布式配置则可能引入许多额外复杂度。出于这个原因，常识告诉我们应该将数据库放在单个节点上（采用垂直扩展策略），直到高扩展性或者高可用性的需求迫使其不得不改成分布式。\n可维护性 可维护性一般关注软件系统的三个设计原则：\n 可操作性（Operability）：便于运维团队保持系统平稳运行 简单性（Simplicity） ：从系统中消除尽可能多的 复杂度（complexity），使新工程师也能轻松理解系统（注意这和用户接口的简单性不一样） 可演化性（evolvability） ：使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配。也称为 可伸缩性（extensibility） 、可修改性（modifiability） 或 可塑性（plasticity）  ","date":"2022-02-13T11:13:32+08:00","permalink":"https://huangkai1008.github.io/p/%E5%8F%AF%E9%9D%A0%E5%8F%AF%E6%89%A9%E5%B1%95%E4%B8%8E%E5%8F%AF%E7%BB%B4%E6%8A%A4%E7%9A%84%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F/","title":"可靠、可扩展与可维护的应用系统"},{"content":"数据抽象 数据抽象的必要性 程序中的许多数据都是 复合（compound） 值 ，例如：\n 日期：由年月日组成 经纬度：由经度和纬度组成  数据抽象可以让我们将复合的值作为一个整体操作，不需要关注复合值的具体组成细节；\n数据抽象使程序更容易设计、维护和修改。\n 将程序中处理数据表示方式的部分与处理数据处理方式的部分隔离开来的通用技术是一种强大的设计方法，称为 数据抽象（data abstraction） 。\n 数据抽象在性质上与功能抽象相似。当我们创建一个函数抽象时，一个函数如何实现的细节可以被隐藏，特定函数本身可以被具有相同整体行为的任何其他函数替换。\n换句话说，我们可以做一个抽象，将函数的使用方式与函数实现的细节分开。类似地，数据抽象也可以将复合数据值的使用方式与其构建方式的细节隔离开来。\n数据抽象的实例   rational(n, d) 返回具有分子n和分母d的有理数\nfrom fractions import gcd def rational(n, d): g = gcd(n, d) return (n//g, d//g)   numer(x) 返回有理数x的分子\ndef numer(x): return x[0]   denom(x) 返回有理数x的分母\ndef denom(x): return x[1]   add_rationals(x, y) 实现两个有理数间的加法操作\ndef add_rationals(x, y): nx, dx = numer(x), denom(x) ny, dy = numer(y), denom(y) return rational(nx * dy + ny * dx, dx * dy)   mul_rationals(x, y) 实现两个有理数间的乘法操作\ndef mul_rationals(x, y): return rational(numer(x) * numer(y), denom(x) * denom(y))   print_rationals(x) 打印有理数\ndef print_rationals(x): print(numer(x), \u0026#39;/\u0026#39;, denom(x))   rationals_are_equal(x, y) 判断两个有理数是否相等\ndef rationals_are_equal(x, y): return numer(x) * denom(y) == numer(y) * denom(x)   数据抽象的屏障    抽象层 描述 示例     原始表示（Primitive Representation） 使用语言内建的数据结构和选择符为数据抽象实现选择器和构造器 [n, d] , x[0]   数据抽象（Data Abstraction） 数据抽象的选择器和构造器 rational, numer, denom   用户程序（User Program） 用户计算程序的实现函数 add_rational, mul_rational, rationals_are_equal, print_rational    这些函数由更高抽象级别调用较低抽象级别实现。\n当程序的某个部分可以使用较高层次的函数而转而使用较低层次的函数时，就会发生 抽象屏障违规（abstraction barrier violation）。\n树的抽象实现 树的描述 树的递归描述  一棵树有一个 根标签（root label） 和 分支（branch） 的列表 每个分支自身也是一棵树 一棵没有分支的树被称为 叶子（leaf） 一棵树从根开始  树的相对描述  树中的每个元素称为一个 节点（node） 每个节点都有一个 标签（label） ，标签可以是任何值 一个节点可以是另一个节点的父节点/孩子节点 顶部节点是根节点(root node)  树的实现 def tree(root_label, branches=[]): for branch in branches: assert is_tree(branch), \u0026#39;branches must be trees\u0026#39; return [root_label] + list(branches) def label(tree): return tree[0] def branches(tree): return tree[1:] def is_tree(tree): if type(tree) != list or len(tree) \u0026lt; 1: return False for branch in branches(tree): if not is_tree(branch): return False return True def is_leaf(tree): return not branches(tree) 树的应用 斐波那契树 def fib_tree(n): if n \u0026lt;= 1: return tree(n) else: left, right = fib_tree(n - 2), fib_tree(n - 1) fib_n = label(left) + label(right) return tree(fib_n, [left, right]) 分区树 def partition_tree(n, m): if n == 0: return True elif n \u0026lt; 0 or m = 0: return tree(False) else: left = partition_tree(n - m, m) right = partition_tree(n, m-1) return tree(m, [left, right]) 可变性 对象  对象（object） 是一组数据和 行为（behavior） 的集合，\n一种类型的对象称为 类（class）。\n Python 中的每个值都是一个对象\n 所有对象都有属性 对象通常有关联的方法  ","date":"2022-02-08T11:13:32+08:00","permalink":"https://huangkai1008.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AF%BC%E8%AE%BA-%E6%95%B0%E6%8D%AE%E6%8A%BD%E8%B1%A1/","title":"计算机导论 数据抽象"},{"content":"函数抽象 编程的要素 每个具有描述力的强大的编程语言一般都有这三种机制：\n 原始的表达式（expression）和语句（statement） 组合（combination）的方式 抽象（abstraction）的手段  表达式  表达式 是用于描述计算过程并得出值的公式。\n 表达式的定义   表达式可以通过 操作符（operator） 定义：\n18 + 69 2 ** 100   也可以通过 函数调用(function call) 的方式：\npow(2, 100) max(50, 300)   表达式的调用 add ( 18 , 69 ) ---------- --------- --------- Operator Operand Operand  评估操作符 评估操作数 将运算符（函数）应用于计算后的操作数（参数）  操作符和操作数都属于表达式，所以都需要先计算出值。\n程序（program)  程序通过操作值工作 程序中的表达式求值  表达式: 'a' + 'hoy' 值：ahoy    值（value）  程序操作值，每个值都有自己确定的类型（data type）。\n 命名（name） 名称可以绑定（bind）到值，一种绑定的方法是使用 赋值语句（assignment statement）\nx = 7 ------- ------- Name Value 值可以是任意的表达式。\n命名规范 名称应该传达它们所绑定的值的含义或目的。函数名称通常传达它们的效果、行为或者返回值。\n如果名称代表通用量，则名称可以很短：计数、任意函数、数学运算的参数等。\n n, k, i- 通常是整数 x, y, z- 通常是实数或坐标 f, g, h- 通常是函数  函数  函数是执行特定任务并且可以轻松复用的代码段， 函数使用 参数(argument) 作为输入，将 返回值（return value） 作为输出， 函数提供了编程语言功能抽象的实现。\n 纯函数和副作用 副作用  副作用(side effect) 是指调用一个函数时，除了返回一个值之外，还做了其他一些额外的工作。\n 比较常见的副作用有打印到控制台：\nprint(-1) 纯函数 纯函数（pure function） 只返回值，不含有任何副作用：\ndef add(x, y): return x + y 非纯函数（non-pure function） 含有副作用：\ndef add(x, y): print(x, y) return x + y 函数的描述 def square(x): \u0026#34;\u0026#34;\u0026#34;Returns the square of X.\u0026#34;\u0026#34;\u0026#34; return x * x 对于以上的函数有：\n   概念 描述 示例     定义域(domain) 可能作为参数的所有输入的集合 x是一个数字   值域（range） 可能返回的值的所有输出的集合 square返回一个非负实数   表现（behavior） 纯函数的表现是它在输入和输出之间建立的关系 square返回x的平方    函数的抽象  按照 参数化（parameterization） 抽象 按照 规范（specification） 抽象  函数的设计  每个函数只做一个工作，这个工作可以用一个简短的名称来识别，并且可以在一行文本中进行表征 拒绝重复定义（Don\u0026rsquo;t repect yourself, DRY） 函数需要通用定义，函数的设计需要适应同一功能下可能发生的各种情况  函数定义文档 函数的定义通常包括描述函数的文档，此文档一般被称为 docstring。\n以下的函数示例可以作为参考：\ndef pressure(v, t, n): \u0026#34;\u0026#34;\u0026#34;Compute the pressure in pascals of an ideal gas. Applies the ideal gas law: http://en.wikipedia.org/wiki/Ideal_gas_law Args: v: volume of gas, in cubic meters t: absolute temperature in degrees kelvin n: particles of gas \u0026#34;\u0026#34;\u0026#34; k = 1.38e-23 # Boltzmann\u0026#39;s constant return n * k * t / v 可以通过help(pressure)查看此文档。\n更多参考信息可以查看如下链接：\ndocstring guidelines\n高阶函数  高阶函数（higher-order function） 的特征是：\n 接受另一个函数作为参数 将函数作为返回值  除此之外的函数都被称为 一阶函数（first-order function）\n 柯里化  用高阶函数将一个接受多个参数的函数转换为一个函数链，每个函数接受一个参数。更具体地说，给定一个函数f(x, y)，我们可以定义一个函数g使得g(x)(y)等价于f(x, y)。这里，g是一个高阶函数，它接受单个参数x并返回另一个接受单个参数y的函数。这种转换称为柯里化（curry）。\n 以下为一个柯里化的示例：\ndef curried_pow(x): def h(y): return pow(x, y) return h \u0026gt;\u0026gt; curried_pow(2)(3) 8 递归函数  如果函数体直接或间接调用函数本身，则函数称为 递归（recursive） 函数。\n 递归函数的通用模式  基线条件（base case） ：在没有递归调用的情况下进行计算（最小的子问题） 递归条件（recusive case） : 通过递归调用进行计算（进一步分解问题） 判断是否是符合基线条件的 条件语句（conditional statement）  def sum_digits(n): if n \u0026lt; 10: # BASE CASE return n else: # RECURSIVE CASE all_but_last = n // 10 last = n % 10 return sum_digits(all_but_last) + last 相互递归  当一个递归过程被划分为两个相互调用的函数时，这些函数被称为 相互递归（mutually recursive）。\n def is_even(n): if n == 0: return True else: return is_odd(n - 1) def is_odd(n): if n == 0: return False else: return is_even(n - 1) 树递归  树递归（tree recursion） 中一个函数会多次调用自身。\n def count_partitions(n, m): \u0026#34;\u0026#34;\u0026#34;Count the ways to partition n using parts up to m.\u0026#34;\u0026#34;\u0026#34; if n == 0: return 1 elif n \u0026lt; 0: return 0 elif m == 0: return 0 else: return count_partitions(n - m, m) + count_partitions(n, m - 1) ","date":"2022-02-05T13:35:54+08:00","permalink":"https://huangkai1008.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AF%BC%E8%AE%BA-%E5%87%BD%E6%95%B0%E6%8A%BD%E8%B1%A1/","title":"计算机导论 函数抽象"},{"content":"InnoDB 的索引 一、前言 什么是索引 索引（index） 的出现是为了提高数据查询的效率，索引的实现一般会使用特定的数据结构，我们可以使用不同的数据结构实现不同的索引模型。\n索引的常见模型 索引的常见模型有 哈希表（hash-table） 、有序数组（array） 和 搜索树（search tree）。\n其中哈希表适用于只有等值查询的场景，例如 Memcached 及其他一些 NoSQL 引擎。\n有序数组在等值查询和范围查询场景中的性能都很优秀，但是对于需要更新数据的场景就显得成本太高，所以有序数组索引只适用于静态存储引擎 。\n关于搜索树，我们最熟悉的应该是 二分搜索树（binary-search tree）。如果需要维持 O(log(N)) 的查询复杂度和更新复杂度，则需要维护这个二分搜索树为平衡二叉树。为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的 N 取决于数据块的大小。\n二、InnoDB 的索引模型 ","date":"2020-11-03T08:40:31+08:00","image":"https://blog-1259169620.cos.ap-guangzhou.myqcloud.com/img/%E6%88%AA%E5%B1%8F2022-07-10%2010.15.54.png","permalink":"https://huangkai1008.github.io/p/innodb-%E7%B4%A2%E5%BC%95/","title":"InnoDB 索引"},{"content":"InnoDB 索引页 一、概述 索引页(index page) 是 InnoDB 众多页类型中的一种，因为 InnoDB 的特点是 索引组织表（Index Organized Table） ，所以可以将索引页看成“数据页”。\nInnoDB 的索引页组成如下图：\n InnoDB 数据页结构  可以通过这个表对索引页的各个部分有个基本的了解。\n   名称 中文名 占用空间大小 简单描述     File Header 文件头部 38字节 页的一些通用信息   Page Header 页面头部 56字节 索引页的一些专有信息   Infimum \u0026amp; Supremum 页面中的最小记录和最大记录 26字节 两个虚拟的记录   User Records 用户记录 不确定 用户存储的记录内容   Free Space 空闲空间 不确定 页中尚未使用的空间   Page Directory 页目录 不确定 页中某些记录的相对位置   File Trailer 文件尾部 8字节 校验页是否完整    二、用户记录的存储 用户存储的记录会按照指定的行格式插入到 User Records 部分，但是在开始生成页时，并没有 User Records 部分。每当插入一条记录时，都会从 Free Space 部分申请一个记录大小的空间并划分到 User Records 部分。\n我们这里以 Compact 行格式为例来展开一下。\nInfimum \u0026amp; Supremum InnoDB存储引擎会自动向数据页插入两条记录：Infimum（最小记录）、Supremum（最大记录） 。这两条记录也被称为伪记录/虚拟记录。\n这两条记录的结构十分简单，都是由5个字节的记录头信息和8字节大小的一个固定单词组成。\n Infimum \u0026amp; Supremum \n用户记录和记录头信息 next_record 字段 next_record 表示的是下一条记录的相对位置(地址偏移量)。但需要注意的是，其并不是指向下一条记录的起始部分，而是指向下一条记录的数据内容的起始部分。\n这个属性值有正负之分，例如第一条记录的 next_record 值为 60 （十进制表示）时，则表示从这条记录的真实数据的地址处向后找 60 字节即是下一条记录的真实数据；当第三条记录的 next_record 值为 -112 时，则表示从这条记录的真实数据的地址处向前找 112 字节便是上一条记录的真实数据的起始处。\n这其实也解释了为什么记录的额外信息部分(变长字段的长度列表、NULL值标志位)是按照列的顺序逆序排列的。因为此时数据内容部分中位置靠前的字段与其所对应的长度信息的相对距离更近。根据 局部性原理 可知，此举将可能会提高CPU高速缓存的命中率。\n这里我们可以看到， 用户记录的各个行通过这个字段组成了一个 单向链表 。链表的每个节点的后继节点都是下一个比它大的记录，这里的 “大小” 比的是主键的大小，而不是记录插入的前后顺序。当其中记录发生变化(新增、删除、修改)时，该链表也会适时调整，以满足链表按记录按照主键值从小到大的排序规则。\n特别的，针对这个记录链表而言无论其怎么变化，其表头、表尾永远是固定不变的，分别是Infimum 最小记录和 Supremum 最大记录，这也是此两条伪记录的命名来源。可以看出这两条记录相当于是记录链表的哨兵节点。\nheap_no 字段 该字段表示的是记录在本页中的位置。由于 Infimum最小记录、Supremum最大记录在用户插入的记录的前面，故分别为0、1。故对于用户记录而言，该值从2开始。假设插入了三条记录，记录主键值分别为1，2， 3，那么记录1、记录2、记录3中该字段的值分别为2、3、4。\ndeleted_flag 字段 该字段为记录删除的标志位。当我们删除某记录时，不是直接从硬盘中删除，而是分为两个阶段：\n delete mask 阶段 ： 将该字段的值置为1。 purge 阶段 ：将该记录加入垃圾链表。  对于垃圾链表中记录所占用的空间即为 可重用空间 。这样下次当有新的记录添加进来时，即可通过覆盖的方式来复用这部分存储空间。当然，所谓的垃圾链表也是通过被删除记录的next_record 字段作为指针来链接形成的。\n三、 Page Directory 页目录 用户记录中的各个记录组成了类似单向链表的结构，其中，最小记录、最大记录分别为表头、表尾。我们知道单向链表的查找效率只有 O(N) 级别，如果每次都从表头去查询是很低效的。为此，引入了 Page Directory 。\n页目录简介 首先我们将所有正常的记录（包括 Infimum 和 Supremum 记录，但不包括已经移除到垃圾链表的记录）划分为若干个分组。\n每个分组的最后一条记录（即组内最大的记录）的 n_owned 字段表示该组内共有几条记录。\n将每个组中最后一条记录在页面中的地址偏移量（即该记录的真实数据与页面中第0个字节之间的距离）按顺序存储到靠近页尾部的地方，也就是存到页目录中。页目录中的这些地址偏移量称为槽（Slot） ，各 Slot 根据其所指向的记录按从大到小的顺序在页目录中排列，其中每个槽占用2字节。\n InnoDB Page Directory \n这样我们在该页下如果需要通过主键来查找某条记录时，过程可以分为两步：\n 通过 二分法 确定该记录所在分组对应的槽，然后找到该槽所在分组中主键值最小的记录（前一个槽最大记录主键值加1）。 通过记录的 next_record 属性遍历该槽所在的组中的各个记录。  如何分组 InnoDB 对于每个分组中的记录数有规定：\n Infimum 记录所在的分组只能有1条记录，即只有它自己； Supremum 记录所在的分组的记录数量只能在1~8条记录之间； 其他分组的记录数量只能在是4~8条记录之间。  具体地关于如何分组，基本步骤如下：\n 在初始情况下，一个数据页中只有 Infimum 和 Supremum 这两条记录，它们分别属于两个分组。页目录中也只有两个槽，分别代表 Infimum 记录和 Supremum 记录在页面中的地址偏移量。 之后每插入一条记录，都会从 Slot 0 开始遍历，直至找到第一个指向的记录比该新纪录大的槽。随后将槽所指向记录的 n_owned 记录值加1。 为了避免某个分组内记录数量过多，当分组内的 记录达到8 时，此时如果再向此组内插入一条新记录，会导致此分组拆分为两个组，其中一个组4条另一个组5条记录。这个拆分过程会在页目录中新增一个槽，记录这个新增分组中最大记录的偏移量。  四、Page Header Page Header (页面头) 描述的就是数据页类型的状态信息，下表是对 Page Header 的结构描述。\n   状态名称 占用空间大小 描述     PAGE_N_DIR_SLOTS 2字节 页目录中的槽数量   PAGE_HEAP_TOP 2字节 Free Space剩余空间的起始地址   PAGE_N_HEAP 2字节 第1位表示本记录是否为紧凑型的记录，剩余15位表示本页的堆中记录的数量（包括 Infimum 、Supremum和“已删除”的记录）   PAGE_FREE 2字节 已被删除的记录的链表(即所谓的垃圾链表)的头节点对应记录在页面中的偏移量   PAGE_GARBAGE 2字节 已删除记录占用的字节数   PAGE_LAST_INSERT 2字节 最后插入记录的位置   PAGE_DIRECTION 2字节 记录插入的方向   PAGE_N_DIRECTION 2字节 一个方向连续插入的记录数量   PAGE_N_RECS 2字节 该页中用户记录的数量   PAGE_MAX_TRX_ID 8字节 修改当前页的最大事务id，该值仅在二级索引页面中定义   PAGE_LEVEL 2字节 当前页在 B+ 树中所属的层级   PAGE_INDEX_ID 8字节 索引ID，表示当前页属于哪个索引   PAGE_BTR_SEG_LEAF 10字节 B+ 树叶子节点段的头部信息，仅在 B+ 树的根页面定义   PAGE_BTR_SEG_TOP 10字节 B+ 树非叶子节点段的头部信息，仅在 B+ 树的根页面中定义    参考资料  小孩子 4919. (2020). MySQL 是怎样运行的. 人民邮电出版社.  ","date":"2020-10-27T19:29:31+08:00","image":"https://blog-1259169620.cos.ap-guangzhou.myqcloud.com/img/%E6%88%AA%E5%B1%8F2022-07-10%2010.15.54.png","permalink":"https://huangkai1008.github.io/p/innodb-%E7%B4%A2%E5%BC%95%E9%A1%B5/","title":"InnoDB 索引页"},{"content":"InnoDB 记录存储格式 一、前言 根据 MySQL的基础架构 来看，MySQL 服务端中存储引擎负责数据的读取和写入。不同的存储引擎的形式也是不尽相同，有的存储引擎（比如 Memory 引擎）只把数据存储在内存、并不会持久化到磁盘，而 InnoDB 存储引擎会将数据持久化到磁盘中。\n二、InnoDB 记录格式 InnoDB 页简介 InnoDB 将记录存储在一个固定大小的单元中，这种单元通常被称为 页（page） ，将页作为磁盘和内存交互的基本单位。页的默认大小为16KB，可以通过以下命令查看默认页的大小（单位为字节）：\nmysql\u0026gt;SHOWSTATUSLIKE\u0026#39;innodb_page_size\u0026#39;;+------------------+-------+|Variable_name|Value|+------------------+-------+|Innodb_page_size|16384|+------------------+-------+1rowinset(0.00sec)也就是说，一般情况下，一次至少从磁盘读取16KB 的内容到内存中，一次至少把内存中的16KB 内存刷新到磁盘中。\nInnoDB 行格式 InnoDB 的行格式有4种，分别是 COMPACT 、REDUNDANT、DYNAMIC 、COMPRESSED 。可以通过如下命令查看默认行格式：\nmysql\u0026gt;SHOWVARIABLESLIKE\u0026#39;innodb_default_row_format\u0026#39;;+---------------------------+---------+|Variable_name|Value|+---------------------------+---------+|innodb_default_row_format|dynamic|+---------------------------+---------+1rowinset(0.01sec)可以在创建或修改表的语句中指定记录所使用的行格式。举例来说，我们创建一个示例表并插入样例数据。\nmysql\u0026gt;CREATETABLErecord_format(-\u0026gt;c1VARCHAR(10),-\u0026gt;c2VARCHAR(10)NOTNULL,-\u0026gt;c3CHAR(10),-\u0026gt;c4VARCHAR(10)-\u0026gt;)CHARSET=asciiROW_FORMAT=COMPACT;QueryOK,0rowsaffected(0.02sec) 创建测试表 \nCOMPACT 行格式 COMPACT 行格式的结构大概如下图所示：\n COMPACT 行格式 \n一条记录可以分为两部分：记录的额外信息和记录的真实数据。\n记录的额外信息 变长字段长度列表 MySQL 中有些类型的字段长度是不固定的，比如 VARCHAR(M) 类型、TEXT 等，这就导致每条记录中该字段的「实际」长度可能是不一样的。\n为此，MySQL 在存储这些变长类型的数据时，实际上分成了两部分存储，分别是：\n 真正的数据内容 该数据占用的字节数  在 COMPACT 行格式中，所有变长字段的真实数据占用的字节数都存储在记录的 变长字段长度列表 中。它是以列的 逆序 存储表中变长字段的实际长度的。\n因为我们使用的是 ascii 字符集，每个字符只需要一个字节来编码，所以对于表中的第一条记录有：\n 变长字段长度列表 \n变长字段 c1、c2、c4 所占用的字节数分别为 4、2、1，以逆序存放在变长字段长度列表表示为 010304。\n例如某个字符集最多需要 $W$ 字节来表示一个字符，变长类型 VARCHAR(M) 表示最多可以存储 $M$ 个字符，所以这种类型能表示的字符串最多占用的字节数就是 $M \\times W$ 。\n再假设该变长字段实际存储的字符串占用的字节数是 $L$ 。\n如果 $M \\times W \\leq 255$，那么使用1字节来表示真实数据占用的字节数；\n如果 $M \\times W \u0026gt; 255$：\n $L \\leq 127$ : 使用1字节来表示真实数据占用的字节数； $L \u0026gt; 127$：使用2字节来表示真实数据占用的字节数。  值得注意的是，变长字段列表中只存储非 NULL 的列的内容长度。\nNULL 值列表 MySQL 中有些列是允许为 NULL 的，如果这些列很多、每个 NULL 值都在表中存储的话会很占用空间。Compact 把这些 NULL 统一管理了起来，放到了 NULL 值列表。\n它的处理过程如下：\n 统计表中允许为 NULL 的列： 若列都不允许为 NULL，则 NULL 值列表就不存在了；否则，以一个二进制位来表示一个允许为空的列，仍是逆序排列，其中 1 表示 NULL，0 表示非 NULL。 若 NULL 值列表不足整数字节，在高位补 0。  以第二条数据为例 c1、c3、c4 允许为 NULL，并且c3、c4的值是NULL。\n 第2条数据 \n NULL值列表 \n记录头信息 记录头信息由固定的5字节组成，用于描述记录的一些属性。\n详细信息如下表:\n   名称 大小（位） 描述     预留位1 1 未使用   预留位2 1 未使用   deleted_flag 1 标记该记录是否被删除   min_rec_flag 1 B+ 树每层非叶子节点中的最小记录都会添加该标记   n_owned 4 当前记录拥有的记录数   heap_no 13 当前记录在页面堆中的相对位置   record_type 3 当前记录的类型   next_record 16 下一条记录的相对位置    记录的真实数据 除了用户自定义的列外，InnoDB 会为每个记录添加 隐藏列，具体如下表所示：\n   列名 是否必需 占用空间 描述     row_id 否 6 字节 行ID，标识唯一一条数据   trx_id 是 6字节 事务ID   roll_pointer 是 7字节 回滚指针    说起 row_id，有必要提一下 InnoDB 的主键生成策略，它遵循如下顺序：\n 优先使用用户定义的主键 若未定义主键，则选取唯一键作为主键 若无唯一键，添加 row_id 作为主键  即，当我们新建一个表时，若没有指定主键（Primary Key），InnoDB 会选择一个唯一键（Unique Key）作为主键，如果表中唯一键也没定义，则就要添加一个隐藏列 row_id 来充当主键了。\nREDUNDANT、DYNAMIC、COMPRESSED 行格式 REDUNDANT 是一种比较原始的行格式，现在已经用的很少了，它是非紧凑的。COMPACT 、DYNAMIC、COMPRESSED 都是较新的紧凑的行格式。\n像现在用的较多的 5.7以及8.0版本的MySQL ，默认行格式都是 DYNAMIC 。\nDYNAMIC 和 COMPRESSED 行格式类似于 COMPACT ，主要区别在于行溢出的处理。\n另外，COMPRESSED 行格式还会采用压缩算法对页面进行压缩。\n行溢出 我们知道，页的大小是有限的，假设页的大小为16KB， 那么当单行的数据超出了页的最大范围，那么就会产生行的溢出。对于这种情况，各种行格式有着不同的处理方法。\n对于Compact和Redundant行格式来说，如果某一列中的数据非常多的话，在本记录的真实数据处只会存储该列的前 768 个字节的数据和一个指向其他页的地址，然后把剩下的数据存放到其他页中。\n而Dynamic和Compressed行格式会把所有的字节都存储到其他页面中，只在记录的真实数据处存储其他页面的地址。·\n参考资料  小孩子 4919. (2020). MySQL 是怎样运行的. 人民邮电出版社. InnoDB Page Structure  ","date":"2020-10-26T08:05:31+08:00","image":"https://blog-1259169620.cos.ap-guangzhou.myqcloud.com/img/compact%E8%A1%8C%E6%A0%BC%E5%BC%8F.png","permalink":"https://huangkai1008.github.io/p/innodb-%E8%AE%B0%E5%BD%95%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/","title":"InnoDB 记录存储格式"},{"content":" IP 网际协议（Internet Protocol） 是网络层的重要协议。在今天，有两个版本的 IP 正在使用，一个是现阶段仍广泛部署的 IPv4 [RFC 791]，另一个是 IPv6 [RFC2460; RFC 4291]。\n一、IPv4 数据报格式 IPv4 数据报中的关键字段有：\n 版本号(version) ：长度为 4 bit ，规定了数据报的 IP 协议版本。 首部长度（Header Length） ：长度为 4 bit ，因为一个 IPv4 数据报可能包含可变数量的选项，所以需要用此字段来确定数据报中载荷（例如在这个数据报中被封装的运输层报文段）实际开始的地方。当 IP 数据报不包含选项时，首部长度一般为 20 字节。 服务类型（Type of service, TOS） ：用来区分不同类型的 IP 数据报，例如可以区分实时数据报和非实时数据报。 数据报长度（Datagram length）：长度为16 bit ，标识 IP 数据报的总长度（首部加上数据），用字节来计量，所以 IP 数据报的理论最大长度为 2 ^ 16 - 1 = 65535 字节。 标识（Identifier） 、标志（Flags） 、 片位移（Fragmentation offset） ：这三个首部字段与 IPv4分片有关。 寿命(Time-to-live, TTL) ：此字段用来防止数据报在网络中无限循环。当一台路由器处理数据报时，TTL 的值减1，当 TTL 为0时，该数据报必须丢弃。 协议（Upper-layer protocol） ：该字段值标识了此数据报应该交给哪个特地的上层传输层协议。 首部检验和（Header checksum） ：此字段用于帮助路由器检测收到的 IP 数据报中的比特错误。 源和目的 IP 地址（Source and destination IP addresses） ：当源生成一个数据报时，在源 IP 地址字段插入它的 IP 地址，在目的 IP 地址字段插入其最终目的地的地址。 选项（Options） 数据/有效载荷（Data/Payload） ：IP 数据报的数据字段包含要交付给目的地的运输层报文段，也可以承载例如 ICMP 报文。  二、 IPv4 数据报分片 一个链路层帧可以承载的最大数据量叫做 最大传送单元（Maximum Transmission Unit, MTU） 。MTU 严格限制着 IP 数据报的长度，如果一个 IP 数据报的长度大于 MTU，则需要进行分片（fragment）。\n三、 IPv4 地址 主机与链路之间的边界叫做 接口（interface） 。对于路由器来说，路由器必须拥有两条及以上的链路与它连接。路由器与它的任意一条链路之间的边界也叫做接口。因此，一台路由器有多个接口。\nIP 要求每台主机和路由器接口拥有自己的 IP 地址，因此，从技术上来讲，一个 IP 地址与一个接口相关联，而不是与包括该接口的主机或路由器相关联。\nIPv4 地址的格式 每个 IP 地址（Internet Protocol address） 长度为 32 比特（等价为 4 字节），通常按照 点分十进制记法（dotted-decimal notation） 记录。\n所谓点分十进制记法，即32 个二进制位分成了 4 个八位组（1 个八位组 = 8 个二进制位），每个八位组转换成了十进制并由句点（点）分隔。 每个八位组值的范围从 0 到 255（十进制）或从 00000000 到 11111111（二进制）。\n10. 1. 23. 19 (decimal) 00001010.00000001.00010111.00010011 (binary)  IPv4 地址编址方式 IP 地址的编址方式经历了三个历史阶段：\n 分类 子网划分 无分类  分类  IP地址由两部分组成，网络号和主机号，其中不同分类具有不同的网络号长度，并且是固定的\n 网络号(net-id)：标志主机或路由器连接的网络，一个网络号在整个因特网内是唯一的\n  主机号(host-id)：标志该主机（或路由器）。一个主机号在它前面的网络号所指明的网络范围内必须是唯一的\n 简而言之，IP 地址 ::= {\u0026lt; 网络号 \u0026gt;, \u0026lt; 主机号 \u0026gt;}\n根据 IP 地址的范围，由此便划分出A、B、C三类及特殊地址D、E：\n   类别 起始位 开始 结束 点分十进制掩码     A 0 0.0.0.0 127.0.0.0 255.0.0.0   B 10 128.0.0.0 191.255.0.0 255.255.0.0   C 110 192.0.0.0 223.255.255.0 255.255.255.0    子网划分  主机号有N位，那么这个地址中，就只能有2 ** n − 2个主机，因为其中全0作为网络地址，全1作为广播地址。 将IP地址与子网掩码做与运算，如果得出的结果一样，则这两个IP地址是同一个子网当中。   子网掩码  子网掩码(subnet mask)又叫网络掩码、地址掩码、子网络遮罩，它是一种用来指明一个IP地址的哪些位标识的是主机所在的子网，以及哪些位标识的是主机的位掩码。\n 通常情况下，子网掩码的表示方法和地址本身的表示方法是一样的。在IPv4中，就是点分十进制四组表示法（四个取值从0到255的数字由点隔开，比如255.128.0.0）或表示为一个八位十六进制数（如FF.80.00.00，它等同于255.128.0.0），后者用得较少。\n另一种更为简短的形式叫做无类别域间路由（CIDR）表示法，它给出的是一个地址加上一个斜杠以及网络掩码的二进制表示法中“1”的位数（即网络号中和网络掩码相关的是哪些位）。例如，192.0.2.96/28表示的是一个前28位被用作网络号的IP地址（和255.255.255.240的意思一样）。\n子网掩码是由32位二进制数字组成的四组数字，左边是网络位，用二进制数字1表示，1的个数等于网络位数的长度，右边是主机位，用二进制数字0表示，0的个数等于主机位的长度。\n当给定一个IP地址后，我们通过相应的子网掩码即可得出该地址所在网络的网络号位数，以此判断该网络能够容纳的机器的个数（即主机号位数）。另外的一个作用就是可以通过运算判断两台机器是否处在同一子网。\n特点 ：\n 与IP地址一一对应 1和0永远是连续的，不会交叉出现 左边永远是1，右边永远是0  广播地址(Broadcast address)  广播地址是专门用于同时向该网络中所有主机进行广播的一个地址。这就好像我们去收听一个广播频道，广播频道本身就是一个广播地址，播音员向这个地址去进行推送，那么只要能够收到这个频道的听众就都能够听到广播。那么这个广播的覆盖面到底有多广呢，这还是取决于我们的网络号。我们知道，一个完整的IP地址是由网络号和主机号两部分组成的，那么广播的覆盖范围就是其所在网络下的所有主机。\n 只要把主机号所在的二进制位全部变为1即可得到广播地址。\n 局域网地址：192.168.211.32/24（斜杠后的数字代表子网掩码的二进制位数，那么主机号的位数为32-24=8），所以广播地址为：192.168.211.255  ","date":"2020-10-17T21:07:31+08:00","image":"https://blog-1259169620.cos.ap-guangzhou.myqcloud.com/img/IPv4_Packet.png","permalink":"https://huangkai1008.github.io/p/ip/","title":"IP"},{"content":"网络层 一、概述 在网络中的每一台主机和路由器都有一个网络层部分。网络层可以被分解为两个相互作用的部分，即 数据平面（data plane） 和 控制平面(control plane) 。\n转发和路由选择 网络层的作用从表面上来看极为简单，即将分组从发送主机移动到接收主机。 为此，需要使用两种重要的网络层功能：转发（forwarding） 和 路由选择(routing) 。\n转发  转发 是指将分组从一个输入链路接口转移到适当的输出链路接口的路由器本地动作。转发是数据平面实现的唯一功能，通常由硬件来实现。\n 路由选择  路由选择 是指确定分组从源到目的地所采取的端到端路径的网络范围处理过程。计算这些路径的算法被称为 路由选择算法（routing algorithm） 。此功能在控制平面由软件实现。\n 网络服务模型  网络服务模型（network service model） 定义了分组在发送与接收端系统之间的端到端运输特性。\n 因特网的网络层提供了单一的服务，称为 尽力而为服务（best-effort service） 。 高情商说法： “尽力而为”， 低情商说法： “根本无服务”。\n二、路由器的工作原理 路由器有4个组件：\n  输入端口（Input port） ：\n 执行查找功能； 执行终结入物理链路的物理层功能； 与位于入链路远端的数据链路层交互来执行数据链路层功能    交换结构(Switching fabric) 将输入端口连接到输出端口，是网络路由器的网络。\n  输出端口（Output port） 存储从交换结构接收的分组，并通过执行链路层和物理层功能将分组在输出链路上传输。当链路是双向时，输入端口和输出端口将成对出现。\n  路由选择处理器（Routing processor） 执行控制平面功能。\n 在传统路由器中，执行路由选择协议，维护路由选择表与关联链路状态信息，并计算转发表； 在 SDN 路由器中，负责与远程控制器通信，接收远程控制器计算的转发表，并安装在输入端口。    输入端口、输出端口和交换结构由硬件实现，控制平面由软件在路由选择器上执行。\n","date":"2020-10-17T21:07:31+08:00","image":"https://blog-1259169620.cos.ap-guangzhou.myqcloud.com/img/Internet_Protocol_Analysis_-_Transport_Layer.png","permalink":"https://huangkai1008.github.io/p/%E7%BD%91%E7%BB%9C%E5%B1%82/","title":"网络层"},{"content":"一、概述 运输层协议为运行在不同主机上的应用进程之间提供了 逻辑通信（logic communication） 功能。\n通过逻辑通信，运行不同进程的主机好像直接相连一样。应用进程使用运输层提供的逻辑通信功能彼此发送报文，而无须考虑承载这些报文的物理基础设施的细节。\n端口号 端口号是一个16比特的数，其大小在 0 ~ 65535 之间。\n0 ~ 1023 范围的端口号称为 周知端口号（well-known port number） ，是受限制的，这些端口号一般保留给 HTTP 和 FTP 之类的周知应用层协议。\n多路复用和多路分解 在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息从而生成报文段，然后将报文段传递到网络层，所有这些工作称为 多路复用（multiplexing） 。\n将运输层报文段中的数据交付到正确的套接字的工作称为 多路分解（demultiplexing） 。\n多路复用的实现 运输层多路复用的要求和实现对应是：\n  套接字有唯一标识符 \u0026ndash; 源端口号字段（source port number field）\n  每个报文段有特殊字段来指示该报文段所要交付的字段 \u0026ndash; 目的端口号字段（destination port number field）\n  多路分解的实现 在主机上的每个套接字能够分配一个端口号，当报文段到达主机时，运输层检查报文段中的目的端口号，并将其定向到相应的套接字。然后报文段中的数据通过套接字进入所连接的进程。\n二、UDP UDP 是一种不提供不必要服务的轻量级运输协议，它仅提供最小服务。\nUDP 的特点   UDP 是无连接的，在两个进程通信前没有握手过程。 因此 UDP 不会引入建立连接的时延。\n  UDP 没有连接状态。 对应上一点提到的，因为 UDP 是无连接的，所以 UDP 不需要维护连接状态。\n  UDP 提供不可靠数据服务。 当进程将一个报文发送进 UDP 套接字时，UDP 协议并不保证该报文将到达接收进程。除此之外，UDP 也不能保证报文的到达顺序，意味着到达接收进程的报文可能是乱序到达的。\n  应用层控制可以做到更加精细。 UDP 协议不包括拥塞控制策略，意味着 UDP 的发送端可以用选定的任意速率发送数据。应用层有着更大的实现自由，例如一些实时应用可以使用 UDP ，并作为应用的一部分来实现所需的、超出 UDP 的额外功能。\n  分组首部开销小。 对比 TCP 协议有着20字节的首部开销，UDP 仅有8字节的首部开销。\n  UDP 数据报结构 UDP 数据报（UDP datagram） 包含 报头（datagram header） 和 数据字段(data section) 两部分。\n UDP Datagram \nUDP 协议头 UDP 协议头包含4个字段，分别是源端口、目的端口、长度和校验码，其中每一个字段都占16bit，即2个字节。\n 源端口（source port） ：可选字段，它表示发送方进程的端口号，并且应假定为在需要时要回复的端口。 目的端口（target port） ：必需字段，数据报接收方的端口号。 长度（length） ：协议头和数据报中数据的字节长度。最小长度为8字节，即标头的长度。 校验和（checksum）：用于协议头和数据的差错检测。在IPv4中可选，在IPv6中是必需的。  对于如下的一个使用 Wireshark 抓包的例子\n UDP header example \n上述 UDP 首部中四个字段对应的值如下：\n   字段 数据     源端口 0x1f5d=8029   目的端口 0x0747=1863   长度 0x0023=35   校验和 0x9019    UDP 校验和 UDP 校验和提供了差错检测功能，校验和用于确定当 UDP 报文段从源到目的地移动时，其中的比特是否发生了改变。\n发送方的 UDP 对报文段中的所有16比特字的和进行反码运算，求和时遇到的任何溢出都会被回卷，得到的结果放在校验和字段。\n三、可靠数据传输 可靠数据传输协议（reliable data transfer protocol） 为上层实体提供的服务抽象是：数据可以通过一条可靠的信道进行传输。借助于可靠信道，传输数据比特就不会受到损坏（由0变为1，或者相反）或丢失，而且所有数据都是按照其发送顺序进行交付。\n我们从简单的场景渐渐过渡到复杂的场景，看如何实现可靠数据传输协议。\n1. 经完全可靠信道的可靠数据传输：1.0 在这个场景下，我们假设底层信道是完全可靠的，并且接收端的接收速率可以和发送端的发送速率同步。\n rdt 1.0 fsm \nrdt 1.0 发送端在收到发送数据的事件（rdt_send(data)） 后，把数据分割成一个个分组，并开始发送数据。\nrdt 1.0 接收端在收到接收数据的事件（rdt_rcv(packet)）后，从分组中提取数据，并把数据发送给上层。\n2. 经具有比特差错信道的可靠数据传输：2.0 底层信道更为实际的模型是分组中的比特可能受损的模型。在这个场景下，我们还是假设发送的分组依然按序交付。\nARQ 协议的定义 在生活中两人打电话的场景也和此场景相近。假设 A 和 B 正在通电话，如果 A 说完一段话后，B 清楚地听到后会回复“好的”，如果 B 觉得 A 讲得含混不清，B 会回复 A “请重复一遍，我没听清”。回复“好的”可以视为 肯定确认（positive acknowledgment） ，回复“请重复一遍，我没听清楚”可以视为 否定确认（negative acknowledgment） 。\n接收端可以通过这种方式使得发送端知道哪些内容被正确接收，哪些内容接收有误并需要重传。在计算机网络环境中，基于这种机制的可靠数据传输协议称为 自动重传请求（Automatic Repeat reQuest, ARQ）协议 。\nARQ 协议的实现 ARQ 协议需要三种协议功能来实现。\n  差错检测 和 UDP 的校验和功能实现类似，我们可以通过增加校验和字段的方式来实现差错检测。\n  接收方反馈 在通电话场景下的 ACK （肯定确认） 和 NAK （否定确认）可以实现接收方反馈的功能。\n  重传 接收方收到有差错的分组时，发送方将重传该分组。\n   rdt 2.0 fsm \n当发送方处于等待 ACK 或 NAK 的状态时，它不能从上层获得更多的数据，也即此时rdt_send事件不会发生。因此，除非发送端确认接收端已经正确地收到它当前发送的数据，发送端是不会发送新数据的。实现此类行为特征的协议被称为 停等协议（stop-and-wait protocol） 。\n处理ACK/NAK分组受损的场景 rdt 2.0 的实现没有考虑ACK或者NAK分组受损的可能性，在这种场景下，发送端无法知道接收端是否成功接收了上一块发送的数据。\n我们的解决方案是在数据分组中增加一个新字段，让发送端对其数据分组编号，即将发送数据分组的 序列号（sequence number） 放在该字段。\nrdt 2.0 作为停止等待协议的一个简单实现，序列号的长度是1位就够了。\n rdt 2.1 sender fsm \n rdt 2.1 receiver fsm \nrdt 2.1 在发送端和接收端均使用了 ACK/NAK，当接收端收到失序分组时，接收端发送 ACK 。当受损分组到达接收端时，接收端发送 NAK。\nrdt 2.2 要做的改进是当受损分组到达接收端时，接收端不发送 NAK，取而代之的是发送一个对最近正确收到的数据的 ACK 。这时需要给 ACK 分组也添加序列号，当发送端收到这个 ACK 时，发送端可以根据 ACK 分组的序列号去判断这个 ACK 分组代表的是接收端正确接收了它刚发送的数据亦或是接收端正确接受了它上一次发送的数据。 当发送端收到两个对同一个分组确认的 ACK 时，即收到重复的 ACK ，发送端就可以知道接收端未能正确收到被确认两次的分组的下一个分组。\n rdt 2.2 sender fsm \n rdt 2.2 receiver fsm \n3. 经具有比特差错的丢包信道的可靠数据运输：3.0 这个场景下底层信道不但会产生比特受损外，还会有丢包的现象。所以协议现在必须处理另外两个关注的问题：\n 怎么检测丢包 发生丢包后如何处理  发送端可以选择一个合理的时间值，如果在这个时间段内，它没有收到这个分组的 ACK ，则重传该分组。即使在这种情况下引入了 冗余数组分组（duplicate data packet） 的可能性，但是 rdt 2.2 已经使用序列号处理冗余分组的情况。\n实现基于时间的重传机制，需要一个 倒计数定时器（countdown timer） ，在一个给定的时间量过期后，可中断发送端。因此发送端需要以下功能：\n 每次发送一个分组（包括第一次分组和重传分组），便启动一个定时器 响应定时器中断（采取适当的动作） 终止定时器   rdt 3.0 fsm sender \n因为分组序号在0和1之间交替，所以 rdt 3.0有时候被称为 比特交替协议（alternating-bit protocol） 。\n4. 流水线可靠数据传输协议 rdt 3.0 采用的是停等协议，这样会导致信道的利用率很低，性能会非常差。\n pipelined protocol vs Stop-and-wait protocol \n可以使用 流水线（pipelining) 技术使得分组可以同时发送，以提高性能。实现流水线技术的要点有：\n 序列号的范围需要增加，因为每个传送途中（非重传）的分组需要独一无二的序列号，而且同时可能存在多个在传送的未确认报文。 发送端和接收端可能需要缓存多个分组，发送端至少需要缓存那些已发送但是还未确认的分组，接收端可能需要缓存那些已经正确接收的分组。 所需序列号范围和缓冲的要求取决于数据传输协议如何处理丢失、损坏以及延时过大的分组。解决流水线的差错恢复有两种基本方法： a. 回退 N 步（Go-Back-N, GBN） b. 选择重传（Selective Repeat, SR）  回退N步 在 GBN 协议中，发送端可以在不需要等待收到 ACK 的情况下，同时发送 N 个分组，这意味着发送端最多能保持 N 个未收到 ACK 的分组，N 也被称为滑动窗口的大小。GBN 协议也常被称为 滑动窗口协议（sliding-window protocol） 。\n Sender’s view of sequence numbers in Go-Back-N \nbase 定义为最小的未收到 ACK 的分组的序列号，nextseqnum 定义为下一个将被发送的分组的序列号。\n区间 [0, base - 1] 定义为已经发送并且已经收到 ACK 的分组序列号。 区间 [base, nextseqnum - 1] 定义为已经发送但是还未收到 ACK 的分组序列号。 区间 [nextseqnum, base + N - 1] 定义为那些要被立刻发送的分组序列号。 区间 [base + N, +∞] 定义为待发送的分组序列号，需要等到序列号为 base 的分组收到 ACK 后，整个滑动窗口向前滑动，base + N 的分组才能被发送。\n GBN sender \n当发送端的上层调用 rdt_send() 时，发送端首先会检查发送窗口是否已满，如果窗口已满，则拒绝发送分组。当超时事件发生时，发送端启动定时器，且会重新发送所有之前已发送过但未收到 ACK 的分组(即区间 [base, nextseqnum - 1]内的分组）。\n当收到某个分组的 ACK 时，还有已被发送且未收到 ACK 的分组，发送端需要重启定时器。如果没有已发送但未被确认的分组，停止该计时器。\n GBN receiver \n假设接收端已经接收到前 n - 1 个分组，那么接收端下一个期待的待接收分组的序列号就为 n 。接收端会丢弃所有下一个到来的序列号非 n 的分组，并重新发送最近收到的分组的 ACK （在这个例子中为：ACK n - 1）。GBN 在这种场景下使用 累积确认（cumulative acknowledgments） 。\n选择重传 GBN 协议潜在地允许发送方用多个分组 “填充流水线” ，因此避免了停等协议中所提到的信道利用率问题。然而 GBN 本身也存在着性能问题，特别是当前网络的带宽延时乘积和滑动窗口 N 都很大时，单个分组的出错就会引起 GBN 重传大量分组，这在大部分情况是没有必要的。随着信道差错率的增加，滑动窗口中便会塞满大量重传的分组。\n顾名思义，选择重传协议只会重传一些接收端未正确收到的分组。这种个别的、按需的重传要求接收方逐个地确认正确接收的分组。与 GBN 不同的是，它的滑动窗口中会包含一些被 ACK 过的分组。\n 选择重传（SR) 发送端与接收端的序号空间 \nSR 接收端将确认一个正确接收的分组而不管其是否是按序的。失序的分组将被缓存直到所有丢失分组（即序号更小的分组）都被收到为止。例如发送端发送了5个分组，序列号分别为 {0, 1, 2, 3, 4}，但是分组 0 丢失了，其它4个分组被成功接收。那么这4个分组将被接收端缓存，并且发送相应的 ACK 给发送端，然后等待分组0，当分组0重传并且成功收到后，接收端将会把这5个分组一起交付给上层。\nSR 协议中发送端的事件与动作包括：\n 从上层收到数据 。当从上层接收到数据后，SR 发送端检查下一个可用于该分组的序号。如果序号位于发送端的滑动窗口内，则将数据打包并发送；否则就像在 GBN 中一样，要么将分组缓存，要么将其返回给上层以便以后传输。 超时 。这里再次使用定时器防止丢失分组。在这个场景下需要每个分组拥有自己的逻辑定时器，因为超时发生后只能发送一个分组。可以使用单个硬件定时器模拟多个逻辑定时器的操作。 收到 ACK 。如果收到 ACK ，倘若该分组序号在窗口内，则 SR 发送端将那个被确认的分组标记为已接收。如果该分组的序号等于 send_base ，则窗口基序号向前移动到具有最小序号的未确定分组处。如果窗口移动了并且有序号落在窗口内的未发送分组，则发送这些分组。  SR 协议中接收端的事件与动作包括：\n 序号在 [rcv_base, rcv_base + N - 1] 内的分组被正确接收。 在此情况下，收到的分组落在接收端的窗口内，一个选择 ACK 被会送给发送端。如果该分组以前未被收到过，则缓存该分组。如果该分组的序号等于接收窗口的基序号（rcv_base） ，则该分组以及以前缓存的序号连续的分组交付给上层。然后，接收窗口按向前移动分组的编号向上交付这些分组。 序号在 [rcv_base - N, rcv_base - 1] 内的分组被正确接收。 在此情况下，必须产生一个 ACK ，即使该分组是接收端以前已经确认过的分组。 其他情况。 忽略该分组。  值得注意的是，对于 SR 协议而言，窗口大小必须小于等于序号空间大小的一半。\n四、TCP TCP 的特点 面向连接 TCP 是 面向连接的（connection-oriented） ，即在一个应用进程在向另一个应用进程发送数据之前，这两个进程必须要相互握手（handshake） 。握手的意思是它们相互发送某些预备报文段，以建立确保数据传输的参数。作为 TCP 连接建立的一部分，连接的双方都将初始化与 TCP 连接相关的许多 TCP 状态变量。\n值得注意的是，TCP 连接指的不是一条像在电路交换网络中的端到端 TDM 或 FDM 电路。这里的 “连接” 是一条逻辑连接，其共同状态仅保留在两个通信端系统的 TCP 程序中。\n全双工服务 TCP 连接提供的是 全双工服务（full-duplex service） , 如果一台主机上的进程 B 存在一条 TCP 连接，那么应用层数据就可在从进程 B 流向 进程 A 的同时，也从进程 A 流向 进程 B。\n点对点通信 TCP 连接总是 点对点的（point-to-point） ，即 TCP 连接总存在于单个发送方和单个接收方之间。\n面向字节流 TCP 把数据看作一个无结构的、有序的字节流。每个TCP套接口有一个发送缓冲区，如果字节流太长时，TCP会将其拆分进行发送。当字节流太短时，TCP会等待缓冲区中的字节流达到一定程度时再构成报文发送出去，TCP发给对方的数据，对方在收到数据时必须给予确认，只有在收到对方的确认时，本方TCP才会把TCP发送缓冲区中的数据删除。\nTCP 可从缓存中取出并放入报文段中的数据数量受限于 最大报文段长度（Maximum Segment Size, MSS） 。\nTCP 的组成 TCP 连接包括：一台主机上的缓存、变量和与进程连接的套接字，以及另一台主机上的另一组缓存、变量和与进程连接的套接字。\nTCP 报文段结构 TCP 报文段（TCP segment） 包含 报文首部（segment header） 和 数据字段（data section） 两部分。\nTCP 报文首部 TCP 报文首部和UDP 协议头一样包含以下字段：\n 源端口（source port） 目的端口（target port） 校验和（checksum）  除此以外 TCP 报文首部还包含以下字段：\n 序号（sequence number） 和 确认号（acknowledgment number） ：长度都是32bit，被 TCP 发送方和接收方用于实现可靠数据传输服务。 窗口大小（receive window size） ：接收窗口的大小，长度为16bit，此字段指示接收方愿意接受的字节数量。 首部长度（Data offset）：长度为4bit，以32bit为单位计算出的数据段开始地址的偏移值。 选项（options）：可选、不定长字段，该字段用于发送方和接收方协商最大报文段长度（MSS）时，或在高速网络环境下用作窗口调节因子。 标志（flag）：长度为9bit，其中每个bit都是一个控制位。  SYN，为同步标志，用于数据同步； ACK，为确认序号，ACK=1时确认号才有效； FIN，为结束序号，用于发送端提出断开连接； URG，为紧急序号，URG=1是紧急指针有效； PSH，指示接收方立即将数据提交给应用层，而不是等待缓冲区满； RST，重置连接； NS，该标签用来保护不受发送者发送的突发的恶意隐藏报文的侵害； ECE，ECN表示Explicit Congestion Notification，表示TCP peer有ECN能力； CWR，发送者在接收到一个带有ECE flag包时，将会使用CWR 标志。    序号和确认号 TCP 是面向字节流的，序号是建立在传送的字节流上，而不是建立在传送的报文段的序列之上，因此 一个报文段的序号（sequence number for a segment） 是该报文段首字节的字节流编号。\n假设主机 A 上的一个进程想通过一条 TCP 连接向主机 B 上的一个进程发送一个数据流。主机中的 TCP 将隐式地对数据流中的每一个字节编号。假定数据流由一个包含 500, 000字节的文件组成，其 MSS 为1000字节，数据流的首字节编号是 X ，那么该 TCP 实体将为该数据流构建500个报文段，给第一个报文段分配序号 X ，给第二个报文段分配序号 X + MSS * 1，第 N 个报文段分配序号 X + MSS * (N - 1) 。\n从上面例子可以看到，TCP 的确认号从一个随机的值开始，这是为了提高安全性，也可以避免被相同端点之间早期连接的旧报文段混淆。\n确认号是期望从另一方收到的下一个字节的序号。与上文我们讨论的 rdt 不同的是，这里的确认号多加了1。\n例如主机 A 已收到 一个来自主机 B 的包含字节 0 ~ 535 的报文段，以及另一个包含字节 900 ~ 1000 的报文段。由于某种原因，主机 A 还没有收到字节 536 ~ 899 的报文段。在这个例子中，主机 A 为了重新构建主机 B 的数据流，仍在等待字节 536 和其后的字节。因此，A 到 B 的下一个报文段将在确认号中包含 536。因为 TCP 只确认该流中至第一个丢失字节为止的字节，所以 TCP 被称为提供 累积确认（cumulative acknowledement） ，在这里和 GBN 协议有些相似。\nTCP 可靠数据传输的实现 TCP 在 IP 不可靠的服务上创建了可靠数据传输服务。TCP 的可靠数据传输服务确保一个进程从其接收缓存中读出的数据流是无损坏、无间隙、非冗余和按序的数据流。\nTCP 发送方事件 TCP 发送方的三个主要事件分别是\n 从应用层接收数据。 超时。 收到确认。  TCP 通过超时和重复确认两个事件触发重传。\n当定时器超时，TCP 重传具有最小序号但仍未应答的报文段，此表现和 SR 协议相似。 当 TCP 收到多个重复的确认时，TCP 会执行快速重传。\n快速重传 超时重传的问题之一是超时周期可能相对较长，会增加端到端时延。\n我们通过冗余的 ACK 来检测报文段丢失，如果发送方接收到对于相同数据的3个冗余ACK，这说明跟在这个已被确认过三次的报文段之后的报文段很大可能已经丢失。我们在这种情况下执行 快速重传（fast retransmit） ，即在该报文段的定时器过期之前重传丢失的报文段。\nTCP 流量控制 TCP 提供了 流量控制服务（flow-control service） 以消除发送方使接收方缓存溢出的可能性。\nTCP 通过让发送方维护一个称为 接收窗口（receive window） 的变量来提供流量控制，通俗地说，接收窗口用于给发送方提示该接收方还有多少可用的缓存空间。\n由于 TCP 是全双工通信，在连接两端的发送方都各自维护一个接收窗口。\n假设主机 A 通过一条 TCP 连接向主机 B 发送一个文件。主机 B 为该连接分配了一个接收缓存，并用 RevBuffer 来表示其大小。主机 B 上的应用进程不时地从该缓存中读取数据。\n我们定义：\n LastByteRead : 主机B 上的应用进程从缓存读出的数据流的最后一个字节的编号。 LastByteRcvd : 从网络中到达的并且已经放入主机 B 接收缓存中的数据流的最后一个字节的编号。  因为 TCP 不允许已分配的缓存溢出，所以有：\n$$ LastByteRcvd - LastByteRead \\leq RevBuffer $$\n那么接收窗口 rwnd 的值为：\n$$ rwnd = RcvBuffer - \\left[LastByteRcvd - LastByteRead\\right] $$\n注意一种场景，当主机 B 的接收缓存已经存满，使得 rwnd = 0。这种情况下为了避免死锁问题，TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。 如果持续计时器超时，就会发送 窗口探测 ( Window probe ) 报文段，这个报文段只有一个字节的数据，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。\nTCP 连接管理 TCP 建立连接 TCP 连接的创建过程通常被称为 三次握手（three-way handshake）。\n TCP 三次握手 \n一般地，客户端和服务端开始都处于 CLOSED 状态，服务端主动监听某个端口，状态变更为 LISTEN 状态。\n第一步，客户端会发送一个 SYN 报文段。此报文段的 SYN 标志位置为 1，首部的序号字段由随机的初始序号（client_isn）填充，此报文段不包含任何应用层数据。在此报文段发送后，客户端 TCP 状态会变更到 SYN_SENT。\n第二步，当服务端收到客户端的 SYN 报文段 后，服务端会为该 TCP 连接分配 TCP 缓存和变量， 并发送一个 SYNACK报文段 表达对连接请求的允许。此报文段的 SYN 和 ACK 标志位置为 1 ，首部的序号字段由随机的初始序号（server_isn）填充，首部的确认号字段填入客户端的初始序号 + 1 （client_isn + 1），这个报文段也不包含任何应用层数据。在此报文段发送后，服务端 TCP 状态会变更到 SYN_RCVD。\n第三步，在客户端收到 SYNACK报文段 后，客户端也需要为此 TCP 连接分配 TCP 缓存和变量，并发送一个应答报文对服务器的允许连接报文段进行了确认。此报文段的ACK 标志位置为 1 ，SYN 标志位置为1，首部的序号字段是client_isn + 1，确认号字段是server_isn + 1。注意，此报文段可以携带应用层数据。发送此报文段后，客户端状态会变更为 ESTABLISHED，在服务端接收到此报文段后，服务端状态也会变更为 ESTABLISHED。\nTCP 关闭连接 连接双方都可以主动断开连接，断开连接后主机中的资源（即缓存和变量）将被释放。TCP 断开连接的方式通常被称为 四次挥手（four-way handshake）。\n TCP 四次挥手 \n假设 TCP 客户端想要断开连接，它会发送一个 FIN 报文段 ，此报文段的 FIN 标志位置为1，此后客户端进入 FIN_WAIT_1 状态。\n服务端收到客户端的 FIN 报文段 后，就会向客户端发送 ACK 报文段 ，此后服务端进入 CLOSED_WAIT 状态。客户端收到服务端的此 ACK 报文段 后，会进入 FIN_WAIT_2 状态。\n等待服务端处理数据完成后，服务端会发送它自己的 FIN 报文段 ，发送后服务端进入 LAST_ACK 阶段。客户端收到服务端的 FIN 报文段 后，客户端会回复自己的 ACK 报文段 ，之后客户端进入 TIME_WAIT 状态。\n服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，至此服务端已经完成连接的关闭，客户端在经过 2MSL 时间后，自动进入 CLOSED 状态，至此客户端也完成连接的关闭。\nTIME_WAIT 状态的必要性 MSL(Maximum Segment Lifetime) 是 报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。\nTIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以 一来一回需要等待 2 倍的时间。\n关于为什么 TCP 有 TIME_WAIT 状态，最主要的原因应该是 保证连接关闭 。只要客户端等待 2 MSL 的时间，客户端和服务端之间的连接就会正常关闭，新创建的 TCP 连接收到影响的概率也微乎其微，保证了数据传输的可靠性。\n 参考资料  Kurose, J. F., \u0026amp; Ross, K. W. (2018). 计算机网络-自顶而下方法 (7th ed.). 机械工业出版社. Wikipedia : User Datagram Protocol Go-Back-N Protocol Selective Repeat Protocol Wikipedia : Transmission Control Protocol 为什么 TCP 协议有 TIME_WAIT 状态  ","date":"2020-08-18T09:21:31+08:00","image":"https://blog-1259169620.cos.ap-guangzhou.myqcloud.com/img/Internet_Protocol_Analysis_-_Transport_Layer.png","permalink":"https://huangkai1008.github.io/p/%E8%BF%90%E8%BE%93%E5%B1%82/","title":"运输层"},{"content":"HTTP/2 一、概述  HTTP/2 的主要目标是通过支持完整的请求与响应复用来减少延迟，通过有效压缩 HTTP 标头字段将协议开销降至最低，同时增加对请求优先级和服务器推送的支持。 为达成这些目标，HTTP/2 还给我们带来了大量其他协议层面的辅助实现，例如新的流控制、错误处理和升级机制。\n 为了实现 HTTP 工作组设定的性能目标，HTTP/2 引入了一个新的二进制分帧层，该层无法与之前的 HTTP/1.x 服务器和客户端向后兼容，因此协议的主版本提升到 HTTP/2。\n二、HTTP/1.x的缺陷 HTTP/1.x 实现简单是以牺牲性能为代价的：\n 客户端需要使用多个连接才能实现并发和缩短延迟 不会压缩请求和响应首部，从而导致不必要的网络流量 不支持有效的资源优先级，致使底层 TCP 连接的利用率低下  三、二进制分帧层 HTTP/2 所有性能增强的核心在于新的二进制分帧层（Binary framing layer），它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。\n 二进制分帧层 \n这里所谓的“层”，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制: HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。 HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。\n这样一来，客户端和服务器为了相互理解，都必须使用新的二进制编码机制: HTTP/1.x 客户端无法理解只支持 HTTP/2 的服务器，反之亦然。 现有的应用不必担心这些变化，因为客户端和服务器会替我们完成必要的分帧工作。\n数据流、消息和帧  数据流（Stream）：已建立的连接内的双向字节流，可以承载一条或多条消息。\n  消息（Message)：与逻辑请求或响应消息对应的完整的一系列帧\n  帧（Frame）：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流\n 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流：\n 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。   \nHTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。\n四、请求与响应复用 在 HTTP/1.x 中，如果客户端要想发起多个并行请求以提升性能，则必须使用多个 TCP 连接。 这是 HTTP/1.x 交付模型的直接结果，该模型可以保证每个连接每次只交付一个响应（响应排队）。 更糟糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。\nHTTP/2 中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用: 客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。\n \nHTTP/2 中的新二进制分帧层解决了 HTTP/1.x 中存在的队首阻塞问题，也消除了并行处理和发送请求及响应时对多个连接的依赖。 结果，应用速度更快、开发更简单、部署成本更低。\n五、服务器推送 HTTP/2 新增的另一个强大的新功能是，服务器可以对一个客户端请求发送多个响应。 换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外资源，而无需客户端明确地请求。\n \n六、标头压缩 HTTP/2 使用 HPACK 压缩格式压缩请求和响应标头元数据。\n \n参考资料  HTTP/2简介  ","date":"2020-07-10T15:51:57+08:00","image":"https://blog-1259169620.cos.ap-guangzhou.myqcloud.com/img/20211123115225.svg","permalink":"https://huangkai1008.github.io/p/http/2/","title":"HTTP/2"},{"content":"一、概述 应用层包括大多数应用程序使用的协议，用于通过较低级别的协议建立的网络连接提供用户服务或交换应用程序数据。\n网络应用程序体系结构 客户-服务器体系结构  存在总是打开的主机称为服务器（server），服务于其他来自客户（client）主机的请求，此种模式称为客户-服务器体系结构（client-server architecture）\n 特征  客户相互之间不直接通信 服务器具有固定的、周知的地址（IP 地址） 数据中心（data center） 用于扩展  示例  web 应用程序  P2P体系结构  以对等方式进行通信，并不区分客户端和服务端，而是平等关系进行通信。在对等方式下，可以把每个相连的主机当成既是服务端又是客户端，可以互相下载对方的共享文件。此种模式称为端到端体系结构（peer-to-peer architecture, P2P architecture）\n 特征  任意端系统直接通信 对等点从其他对等点请求服务，向其他对等点提供服务 自扩展性（self-scalability）：例如在 P2P 文件共享场景下，尽管每个对等方都由于请求文件产生工作负载，但每个对等方通过向其他对等方分发文件也为文件共享系统增加服务能力  示例  文件共享（BitTorrent） 对等方协助下载加速器（迅雷） 因特网电话和视频应用（Skype）  进程通信 在不同端系统上的进程（process），通过跨越计算机网络发送报文（message）\n客户与服务器进程  在一对进程之间的通信会话场景中，发起通信（即在该会话开始时发起与其他进程的联系）的进程被标识为客户，在会话开始时等待被联系的进程是服务器进程\n 对于 web 而言，浏览器是一个客户进程，Web 服务器是一个服务器进程；\n对于 P2P 文件共享，下载文件的对等方标识为客户，上载文件的对等方标识为服务器。\n进程与计算机网络间的接口 进程通过套接字向网络发送报文和从网络接收报文。\n 套接字（socket） 是同一台主机内应用层与运输层之间的接口。由于该套接字是建立网络应用的可编程接口，因此套接字也称为应用程序和网络之间的应用程序编程接口（Application Programming Interface, API）\n 应用程序开发者可以控制套接字在应用层端的一切，但是对该套接字的运输层端控制仅限于：\n 选择运输层协议 设定运输层一些参数，比如最大缓存和最大报文段长度等  应用程序建立在选择的运输层协议提供的运输层服务之上。\n进程寻址 为了标识接收进程，需要定义两种信息：\n 主机的地址（IP地址） 在目的主机中指定接收进程的标识符（端口号）  运输服务要求 可靠数据传输  如果一个协议确保由应用程序的一端发送的数据正确、完全地交付给该应用程序的另一端，那么就认为此协议提供了可靠数据传输（reliable data transfer）\n 当运输层协议不能提供可靠数据传输时，此协议可能能被容忍丢失的应用（loss-tolerant application） 所接受。\n吞吐量 运输层协议能够以某种特定的速率提供确保的可用吞吐量。使用此类服务，应用程序能够请求 r 比特/秒的确保吞吐量，并且该运输协议能够确保可用吞吐量总是为至少 r 比特/秒。\n具有吞吐量要求的应用程序被称为带宽敏感的应用（bandwidth-sensitive application），例如许多当前的多媒体应用；\n相反地，可以根据当时可用带宽利用可供使用吞吐量的应用被称为弹性应用（elastic application），例如电子邮件、文件传输应用。\n定时 运输层协议也能提供定时保证。这种服务对于实时性的应用十分有吸引力，比如因特网电话、多方游戏和虚拟互动环境等。\n安全性 运输层协议可以提供机密性、数据完整性和端点鉴别等安全性服务。\n二、应用层协议  应用层协议（application layer protocol） 定义了运行在不同端系统上的应用程序进程如何相互传递报文\n 具体定义内容为：\n 交换的报文类型 报文类型的语法 字段的语义 确定一个进程何时以及如何发送报文，对报文进行响应的规则  Web 与 HTTP 电子邮件系统 因特网电子邮件系统（email） 有三个主要组成部分：\n 用户代理(user agent) 邮件服务器（mail server） 简单邮件传输协议（Simple Mail Transfer Protocol, SMTP）  SMTP  SMTP 用于从发送方的邮件服务器发送报文到接收方的邮件服务器，SMTP 使用 TCP 作为它的支撑运输协议\n SMTP有两个部分：\n 运行在发送方邮件服务器的客户端 运行在接收方邮件服务器的服务端  每台邮件服务器同时运行 SMTP 的客户端也运行 SMTP 的服务端，根据邮件服务器的表现是发送/接收邮件决定它是 SMTP 的 客户端/服务端。\n邮件访问协议 与 HTTP 不同的是，HTTP是一个拉协议（pull protocol）， SMTP 是一个推协议(push protocol)，为了从邮件服务器上获取邮件到客户端，需要引入邮件访问协议，当前比较流行的邮件访问协议有：\n 第三版的邮局协议（Post Office Protocol--Version 3, POP3） 因特网邮件访问协议（Internet Mail Access Protocol, IMAP） 基于 Web 的电子邮件（HTTP）  DNS 协议  参考资料  Kurose, J. F., \u0026amp; Ross, K. W. (2018). 计算机网络-自顶而下方法 (7th ed.). 机械工业出版社.  ","date":"2020-06-25T22:20:45+08:00","permalink":"https://huangkai1008.github.io/p/%E5%BA%94%E7%94%A8%E5%B1%82/","title":"应用层"},{"content":"计算机网络 一、概述 网络是 节点（vertex） 与 边（edge） 构成的与大小形状无关的 图（graph）。\n联网的计算机系统，由节点和边构成的网络叫做计算机网络。在这个网络中，节点是计算设备，边是通信链路。\n广义上讲，凡是由能彼此通信的设备组成的网络就叫 互联网（internet） ，互联网把多种不同的网络连接起来，因此互联网是网络的网络\n 互联网 \n以 TCP / IP 协议簇为主的世界范围内的计算机网络称为 因特网（Internet）。\n万维网(World Wide Web, WWW) 是互联网的主要服务，提供网页和音视频等服务\n从关系上来说，互联网（广义）\u0026gt; 因特网 \u0026gt; 万维网\n二、因特网 因特网的构成 因特网包含了全世界数十亿计算设备，在今天，这些设备一般被称为主机（host） 或者端系统（end system），端系统通过通信链路（communication link） 和 分组交换机（packet switch） 连接到一起。\n节点与边  \n如上图所示，从源节点到目标节点传送数据的过程中，源节点/目标节点的节点类别为 主机节点 ，中转节点的节点类别为 数据交换节点 。\n连接节点的边是通信链路，其中主机连接到互联网的链路为 接入网链路（access link） ，分组交换设备间的链路称为 主干链路（backbone link）。\n协议  协议（protocol） 定义了在两个或者多个通信实体之间交换的报文的格式和顺序，以及报文发送和/或接收一条报文或其他事件所采取的动作。\n 协议规范了语法、语义、时序和动作。\n因特网的服务 因特网提供的服务大致分两个部分：\n 使用通信设施进行通信的分布式应用。 通信基础设施为分布式应用提供通信服务（编程接口）。  网络边缘 端系统位于因特网的 边缘（edge） ，端系统也称为主机，即主机 = 端系统。\n网络核心 因特网端系统的分组交换机和链路构建的网状网络被称为网络 核心（core） 。\n通过网络链路和交换机移动数据有两种基本方法：电路交换（circult switching） 和 分组交换（packet switching）。\n以上两种交换方式的详细介绍见电路交换与分组交换。\n接入网  接入网 \nISP  因特网服务提供商（Internet Service Provider, ISP），ISP 可以从互联网管理机构申请到很多 IP 地址，然后一些机构和个人从某个 ISP 获取 IP 地址的使用权，并可通过该 ISP 连接到互联网\n 例如中国移动、中国移动、中国电信就是有名的ISP\n ISP \n三、电路交换与分组交换 电路交换（circuit switching）  电路交换需要建立一条专用的数据通信路径，这条路径上可能包含许多中间节点。这条通信路径在整个通信过程中将被独占，直到通信结束才会释放资源。电路交换适合实时性要求较高的大量数据传输的情况。\n电路交换最显著的特点：独占资源，最典型的电路交换：传统电话网络\n 电路交换中的多路复用（multiplexing）  物理链路的通信能力远远大于一路通信所需要的能力，可以通过多路复用提高信道利用率，同时各个通信线路之间又互不影响\n  频分多路复用（Frequency-Division Multiplexing, FDM） 时分多路复用（Time-Division Multiplexing, TDM） 码分多路复用（Code-Division Multiplexing, CDM） 波分多路复用（Wavelength-Division Multiplexing, WDM）  优势  通信延时小。通信双方通过专用线路进行通信，数据可以直达。当数据传输量较大时，优点将十分显著 线路独占，没有冲突 实时性强。一旦通信线路建立，双方可以实时通信  劣势  线路独占，利用率太低 连接建立时间过长  分组交换（packet switching） 分组 在网络应用中，端系统彼此交换报文（message）。\n 为了从源端系统向目的端系统发送一个报文，源将长报文划分为小的数据块，这些小的数据块被称为分组（packet）\n 在源和目的地之间，每个分组都通过通信链路（communication link） 和 分组交换机（packet switch） 传送，分组以等于该链路最大传输速率的速度传输通过通信链路。\n存储转发传输 多数分组交换机在链路的输入端使用存储转发传输机制。\n 存储转发传输（store-and-forward transmission）：交换机能够向输出链路传输该分组的第一个比特前，必须接收到整个分组\n 优势  线路利用率更高 支持优先级传输 可靠性高 可以实现不同类型的数据终端设置  劣势  存在时延问题 分组必须携带一些控制信息需要额外的开销  节点时延 处理时延(nodal processing delay)  交换机、路由器等网络设备在收到报文后要进行解封装分析首部、提取数据、差错检验、路由选择等处理，此类时间被称为节点处理时延。一般来说，高速路由器的处理时延通常是微秒或者更低的数量级。\n 排队时延（queuing delay）  路由器或交换机等网络设备处理数据包排队所消耗的时间被称为排队时延。\n 排队时延的决定因素  R 链路的带宽(bps) L 数据包的大小(bits) a 数据包的平均到达时长  流量强度与排队时延  假定所有分组都是L比特组成，且队列无限大，则称 La/R 为流量强度 (traffic intensity)\n  La/R ~ 0：近乎为0 La/R -\u0026gt; 1：慢慢增大 La/R \u0026gt; 1：时延将会无穷大  因此：设计系统时流量强度不能大于1\n丢包（packet loss） 实际情况下输出队列容量是有限的，当分组到达时，队列是满的，路由器将会丢弃（drop） 该分组。\n传输时延（transmission delay）  路由器、交换机等网络设备将所有分组的比特推向链路所需要的时间被称为传输时延。\n 如果用 L 比特表示分组的长度，用 R bps(b/s) 表示从路由器A到路由器B的链路传输速率，传输时延是 L/R 。\n即： $$ d_{trans} = \\frac{L}{R} $$\n传播时延（propagation delay）  报文在实际的物理链路上传播数据所需要的时间被称为传播时延。\n 如果 d 是路由器 A 到路由器 B 之间的距离，s 是该链路之间的传播速率（传播速率取决于链路的物理媒体），传播时延是 d/s 。\n即： $$ d_{prop} = \\frac{d}{s} $$\n节点的总时延（total nodal delay） 节点的总时延 为处理时延、排队时延、传输时延和传播时延的和，即： $$ d_{nodal} = d_{proc} + d_{queue} + d_{trans} + d_{prop} $$\n端到端时延 通过由 N 条速率均为 R 的链路组成的路径，此时在源和目的地之间有 N - 1 台路由器，从源到目的地发送一个长度为L的分组，因为存储转发传输机制，假设网络此时是无拥塞的，那么端到端时延是：\n$$ d_{end-end} = N(d_{proc} + \\frac{L}{R} + d_{prop}) $$ 或: $$ d_{end-end} = N(d_{proc} + d_{trans} + d_{prop}) $$\nTraceroute  traceroute命令用于追踪数据包在网络上的传输时的全部路径\n traceroute -m 10 www.baidu.com traceroute to www.baidu.com (183.232.231.172), 10 hops max, 60 byte packets 1 _gateway (10.0.2.2) 0.321 ms 0.249 ms 0.106 ms 2 * * * 3 * * * 4 * * * 5 * * * 6 * * * 7 * * * 8 * * * 9 * * * 10 * * * 四、性能指标 互联网主要的性能指标有速率、带宽、吞吐量和时延等。\n速率  速率（传输速率，transmission rate） 是指计算机网络中的主机在数字信道上，单位时间内从一端传送到另一端的数据量，即数据传输率，也称数据率或比特率，单位为比特/秒（bit/s, bps）\n 不同的链路拥有不同的传输速率，一般讨论传输速率，往往指的是额定速率或标称速率（理想速率），此指标和物理媒体密切相关。\n带宽  带宽（bandwidth） 是指 计算机网络中的主机在数字信道上，单位时间内从一端传送到另一端的最大数据量，即最大速率\n 上行带宽与下行带宽  上行带宽是指用户电脑向网络发送信息时的数据传输速率，下行带宽是指网络向用户电脑发送信息时的传输速率\n 吞吐量  吞吐量（throughput） 是指单位时间内某个信道/端口实际的数据量，可以理解为实际的带宽\n 吞吐量等于瓶颈链路的传输速率，对于n条链路，链路速率分别为R1、R2 \u0026hellip; Rn，吞吐量为：min{R1, R2 \u0026hellip; Rn}\n瞬时吞吐量和平均吞吐量  从服务器到客户机通过计算机网络传送一个大文件，任意时刻客户机接收该文件的速率叫做瞬时吞吐量（instantaneous throughput），假设客户机接收该文件的所有 F 比特用了 T 秒，那么 F/T 就叫做平均吞吐量（average throughput）\n 五、 计算机网络体系结构 协议分层  网络设计者以 分层（layer） 的形式组织 协议（protocol） 以及实现这些协议的网络硬件和软件，各层的所有协议被称为协议栈（protocol stack）\n 优点  各层之间是独立的，某一层不需要知道其下层实现 灵活性好 结构上可分割开 易于实现和维护 能促进标准化工作  潜在缺点  一层可能冗余较低层的功能 某层功能可能需要仅在其他某层才出现的信息（如时间戳值），这违反了层次分离的目标  现在比较常见的一共有三种协议分层模型，分别为OSI 分层模型、五层协议模型（因特网协议栈）、TCP/IP 模型。\n 协议分层 \nOSI 模型 OSI 模型由 应用层（application layer)、表示层（presentation layer）、 会话层（session layer）、运输层（transport layer）、网络层（internet layer）、链路层（link layer）、物理层 （physical layer） 7 个层次组成。\n因特网协议栈 因特网协议栈由 应用层（application layer) 、运输层（transport layer）、网络层（internet layer）、链路层（link layer）、物理层 （physical layer） 5 个层次组成。\nTCP/IP 模型 TCP/IP 模型由应用层（application layer)、运输层（transport layer）、网际层（internet layer）、网络接口层 （network access layer） 4 个层次组成。\n服务和服务访问点 服务(service) 指的是低层实体向上层实体提供他们之间的通信的能力。其中有两个角色，一个是 服务用户（service user） ，一个是 服务提供者（service provider） ，服务提供者向服务用户提供服务。\n原语 原语（primitive） 指的是上层使用下层服务的形式。高层使用低层提供的服务，以及低层向高层提供服务都是通过服务访问原语来进行交互的。\n例如在应用层使用传输层服务的时候，socket API 就是一种原语。\n服务访问点 服务访问点（service access point） 指的是上层使用下层提供的服务通过层间的接口地点。下层的一个实体支撑着上层的多个实体，SAP有标志不同上层实体的作用。\n例如传输层的服务访问点就是 端口（port） 。\n服务类型 服务类型通常有 面向连接的服务（Connection-oriented Service） 和 无连接（Connectionless Service） 的服务两种。\n服务与协议 服务与协议的主要区别在于：\n 服务 : 低层实体向上层实体提供它们之间的通信的能力，是通过原语来操作的，垂直 协议：对等层实体之间在相互通信的过程中，需要遵循的规则的集合，水平  服务与协议的联系在于：\n 本层协议的实现要靠下层提供的服务来实现 本层实体通过协议为上层提供更高级的服务  六、代理服务器  代理服务器（proxy server） 是一种网络服务，允许一个终端（一般是客户端）通过这个服务与另一个终端（一般为服务端）进行非直接的连接。\n 正向代理  正向代理（forward proxy） 是一个位于客户端和目标服务器之间的代理服务器 (中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特殊的配置。\n 反向代理  反向代理（reverse proxy） 代表客户端从一个或多个服务器检索资源。然后这些资源返回给客户端，看起来好像它们来自反向代理服务器本身。主要用于负载均衡。\n 正向代理与反向代理的区别 正向代理代理的对象是客户端，反向代理代理的对象是服务端。\n参考资料  Kurose, J. F., \u0026amp; Ross, K. W. (2018). 计算机网络-自顶而下方法 (7th ed.). 机械工业出版社. Wikipedia : Internet_protocol_suite Computer network Wikipedia : OSI  ","date":"2020-06-17T11:22:54+08:00","permalink":"https://huangkai1008.github.io/p/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","title":"计算机网络"},{"content":"一、域名 网域名称（英语：Domain Name，简称：Domain），简称 域名 、 网域 ，是由一串用点分隔的字符组成的互联网上某一台计算机或计算机组的名称，用于在数据传输时标识计算机的电子方位。域名可以说是一个IP地址的代称，目的是为了便于记忆后者。\n域名的层级 www.example.com 真正的域名是 www.example.com.root ，简写为 www.example.com. 。因为，根域名 .root 对于所有域名都是一样的，所以平时是省略的。\n根域名的下一级，叫做 顶级域名（top-level domain，缩写为TLD） ，比如 .com 、 .net ；\n再下一级叫做 次级域名（second-level domain，缩写为SLD） ，比如 www.example.com 里面的 .example ，这一级域名是用户可以注册的；\n再下一级是 主机名（host） ，比如 www.example.com 里面的 www，又称为 三级域名 ，这是用户在自己的域里面为服务器分配的名称，是用户可以任意分配的。\n 主机名.次级域名.顶级域名.根域名\nhost.sld.tld.root\n  \n二、DNS 域名系统（英语：Domain Name System，缩写：DNS）是一个分布式数据库，提供了域名和 IP地址之间相互转换的服务。\n查询过程 DNS 服务器根据域名的层级，进行 分级查询。\n每一级域名都有自己的 NS（Name Server） 记录，NS记录指向该级域名的域名服务器。这些服务器知道下一级域名的各种记录。\n \u0026ldquo;分级查询\u0026rdquo;，就是从根域名开始，依次查询每一级域名的NS记录，直到查到最终的IP地址\n过程大致为:\n 从\u0026quot;根域名服务器\u0026quot;查到\u0026quot;顶级域名服务器\u0026quot;的NS记录和A记录（IP地址） 从\u0026quot;顶级域名服务器\u0026quot;查到\u0026quot;次级域名服务器\u0026quot;的NS记录和A记录（IP地址） 从\u0026quot;次级域名服务器\u0026quot;查出\u0026quot;主机名\u0026quot;的IP地址   dig math.stackexchange.com ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.11.3-1ubuntu1.15-Ubuntu \u0026lt;\u0026lt;\u0026gt;\u0026gt; math.stackexchange.com ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 50719 ;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 65494 ;; QUESTION SECTION: ;math.stackexchange.com. IN A ;; ANSWER SECTION: math.stackexchange.com. 600 IN A 151.101.193.69 math.stackexchange.com. 600 IN A 151.101.129.69 math.stackexchange.com. 600 IN A 151.101.65.69 math.stackexchange.com. 600 IN A 151.101.1.69 ;; Query time: 74 msec ;; SERVER: 127.0.0.53#53(127.0.0.53) ;; WHEN: Mon Sep 13 10:18:12 UTC 2021 ;; MSG SIZE rcvd: 115 记录类型 域名与IP之间的对应关系，称为记录（record）。根据使用场景，记录可以分成不同的类型（type）。\n   记录类型 记录类型简称 描述     地址记录（Address） A 返回域名指向的IP地址   域名服务器记录（Name Server） NS 返回保存下一级域名信息的服务器地址。该记录只能设置为域名，不能设置为IP地址   邮件记录（Mail eXchange） MX 返回接收电子邮件的服务器地址   规范名称记录（Canonical Name） CNAME 返回另一个域名，即当前查询的域名是另一个域名的跳转   逆向查询记录（Pointer Record） PTR 只用于从IP地址查询域名    传输方式 DNS 可以使用 UDP 或者 TCP 进行传输，使用的端口号都为 53。大多数情况下 DNS 使用 UDP 进行传输，这就要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。在两种情况下会使用 TCP 进行传输：\n 如果返回的响应超过的 512 字节（UDP 最大只支持 512 字节的数据） 区域传送（区域传送是主域名服务器向辅助域名服务器传送变化的那部分数据）  参考资料  【日】户根勤. (2017). 网络是怎样连接的. 人民邮电出版社. Wikipedia : DNS 阮一峰的网络日志: DNS 原理入门  ","date":"2020-06-14T16:02:15+08:00","permalink":"https://huangkai1008.github.io/p/%E5%9F%9F%E5%90%8D%E5%92%8Cdns/","title":"域名和DNS"},{"content":"HTTP 一、概述  超文本传输协议（HyperText Transfer Protocol, HTTP） 是 Web 的核心，HTTP 由客户端程序和服务器程序实现\n HTTP 使用 TCP 作为它的支撑运输协议，因为 HTTP 服务器并不保存关于客户的任何信息，所以 HTTP 是一个无状态协议（stateless protocol）。\n请求和响应报文 客户端发送一个请求报文给服务器，服务器根据请求报文中的信息进行处理，并将处理结果放入响应报文中返回给客户端。\n请求消息（requests） GET / HTTP/1.1 Host: developer.mozilla.org Accept-Language: fr   起始行（start line）：包含一个HTTP方法（method）、请求目标（request target） 和 HTTP 版本 （HTTP version）\n  消息头（headers）： 整个 header（包括其值）表现为单行形式\n  一个空行用来分隔首部和内容主体 Body\n  消息主体（body）\n HTTP Requests Example \n   响应消息(responses) HTTP/1.1 200 OK Date: Sat, 09 Oct 2010 14:28:02 GMT Server: Apache Last-Modified: Tue, 01 Dec 2009 20:18:22 GMT ETag: \u0026#34;51142bc1-7449-479b075b2891b\u0026#34; Accept-Ranges: bytes Content-Length: 29769 Content-Type: text/html \u0026lt;!DOCTYPE html... (here comes the 29769 bytes of the requested web page)  状态行（status line)：  协议版本，通常为 HTTP/1.1. 状态码 (status code)，表明请求是成功或失败。常见的状态码是 200，404，或 302 状态文本 (status text)：一个简短的，纯粹的信息，通过状态码的文本描述，帮助理解该 HTTP 消息   消息头（Headers）： 整个 header（包括其值）表现为单行形式 一个空行用来分隔首部和内容主体 Body 消息主体（body）   HTTP Responses Example \n 二、HTTP 方法    请求方法 描述 RFC 请求具有请求实体 响应具有响应实体 安全方法 是否幂等     GET 请求一个指定的资源 RFC 7231 可选 是 是 是   HEAD 获取报文首部，不返回报文实体主体，主要用于确认 URL 的有效性以及资源更新的日期时间等 RFC 7231 可选 否 是 是   POST 用于将实体提交到指定的资源 RFC 7231 是 是 否 否   PUT 向指定资源位置上传其最新内容 RFC 7231 是 是 否 是   PATCH 对资源进行部分修改 RFC 5789 是 是 否 否   DELETE 删除指定的资源 RFC 7231 可选 是 否 是   CONNECT 要求在与代理服务器通信时建立隧道 RFC 7231 可选 是 否 否   OPTIONS 查询指定的 URL 能够支持的方法 RFC 7231 可选 是 是 是   TRACE 服务器会将通信路径返回给客户端 RFC 7231 否 是 是 是    HTTP方法的安全性 如果说一个 HTTP 方法是安全（safe） 的，是指这是个不会修改服务器的数据的方法。也就是说，这是一个对服务器只读操作的方法。这些方法是安全的：GET，HEAD 和 OPTIONS。所有安全的方法都是幂等的，但并非所有幂等方法都是安全的，例如，PUT 和 DELETE都是幂等的，但不是安全的。\nHTTP方法的幂等性 一个HTTP方法是幂等（idempotent） 的，指的是同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的。换句话说就是，幂等方法不应该具有副作用（统计用途除外）。在正确实现的条件下， GET， HEAD， PUT 和 DELETE等方法都是幂等的，而 POST方法不是。所有的 安全方法也都是幂等的。\n幂等性只与后端服务器的实际状态有关，而每一次请求接收到的状态码不一定相同。例如，第一次调用 DELETE方法有可能返回200，但是后续的请求可能会返回 404 。 DELETE 的言外之意是，开发者不应该使用 DELETE 法实现具有删除最后条目功能的 RESTful API。\n需要注意的是，服务器不一定会确保请求方法的幂等性，有些应用可能会错误地打破幂等性约束。\n 三、HTTP 首部（header)    类型 描述 实例     通用头（General headers） 适用于请求和响应信息的头字段 Date,Cache-Control   请求头（Request headers） 用于表示请求信息的附加信息的头字段 Authorization,User-Agent,Accept-Encoding   响应头（Response headers） 用于表示响应信息的附加信息的头字段 Location,Server   实体头（Entity headers） 用于表示实体（消息体）的附加信息的头字段 Allow,Content-Encoding,Expires, Etag    四、HTTP 状态码（status code）    状态码 含义     1xx(informational response) 告知请求的处理进度和情况   2xx(successful) 成功   3xx(redirection) 需要进一步处理   4xx(client error) 客户端错误   5xx(server error) 服务器错误    五、连接管理  HTTP 1.X 的连接类型 \n非持续连接和持续连接  每个请求及其响应对经一个单独的 TCP 连接发送，此种方式称为使用非持续连接（non-persistent connection），也可以称为短连接；\n多个请求及其响应经过相同的TCP连接发送，此种方式称为使用持续连接（persistent connection），也可以称为长连接、连接保活（keep alive）、连接复用（connection reuse）；\n 这里的持续连接（长连接）和非持续连接（短连接）指的都是TCP连接。\n从 HTTP/1.1 开始默认使用持续连接，如果要断开连接，需要由客户端或者服务器端提出断开，使用 Connection : close；\n在 HTTP/1.1 之前默认使用非持续连接的，如果需要使用持续连接，则使用 Connection : Keep-Alive。\n非持续连接的问题  必须为每一个请求的对象建立和维护一个全新的连接，会产生大量的开销，给 web 服务器带来严重负担 每一个对象经受两倍 RTT（Round-Trip Time, RTT, 即往返时延）的交付时延（一个 RTT 创建 TCP，一个RTT请求和接受一个对象），效率较低  持续连接的问题 持续连接在空闲状态也消耗服务器资源，而且在重负载时，还有可能遭受 DoS 攻击，对于这种情况一般采取的策略是：\n  关闭一些长时间没有发生请求的连接\n  限制每个客户端的最大连接数，避免恶意的客户端影响服务端\n  以Nginx为例 ：\n 可以通过 keepalive_timeout 参数设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源 可以通过 keepalive_requests 参数设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接  六、Cookie 和 Session HTTP Cookies  HTTP Cookie（也叫 Web Cookie 或浏览器 Cookie） 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能\n Cookie 曾一度用于客户端数据的存储，因当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。由于服务器指定 Cookie 后，浏览器的每次请求都会携带 Cookie 数据，会带来额外的性能开销（尤其是在移动环境下）。新的浏览器API已经允许开发者直接将数据存储到本地，如使用 Web storage API （本地存储和会话存储）或 IndexedDB 。\n用途   会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）\n  个性化设置（如用户自定义设置、主题等）\n  浏览器行为跟踪（如跟踪分析用户行为等）\n  创建过程 当服务器收到 HTTP 请求时，服务器可以在响应头里面添加一个 Set-Cookie 选项。浏览器收到响应后通常会保存下 Cookie，之后对该服务器每一次请求中都通过 Cookie 请求头部将 Cookie 信息发送给服务器。另外，Cookie 的过期时间、域、路径、有效期、适用站点都可以根据需要来指定。\nSet-Cookie响应头部和Cookie请求头部 服务器使用 Set-Cookie 响应头部向用户代理（一般是浏览器）发送 Cookie信息。一个简单的 Cookie 可能像这样：\nSet-Cookie: \u0026lt;cookie名\u0026gt;=\u0026lt;cookie值\u0026gt; 服务器通过该头部告知客户端保存 Cookie 信息，客户端得到响应报文后把 Cookie 内容保存到浏览器中：\nHTTP/1.0 200 OK Content-type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry [page content] 现在，对该服务器发起的每一次新请求，浏览器都会将之前保存的Cookie信息通过 Cookie 请求首部字段再发送给服务器：\nGET /sample_page.html HTTP/1.1 Host: www.example.org Cookie: yummy_cookie=choco; tasty_cookie=strawberry 生命周期  会话期 Cookie：浏览器关闭之后它会被自动删除，也就是说它仅在会话期内有效 持久性 Cookie：指定过期时间（Expires）或有效期（max-age）之后就成为了持久性的 Cookie  Set-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; 作用域 Domain 标识 Domain标识指定了哪些主机可以接受 Cookie。如果不指定，默认为当前文档的主机（不包含子域名）。如果指定了 Domain，则一般包含子域名。例如，如果设置 Domain=mozilla.org，则 Cookie 也包含在子域名中（如 developer.mozilla.org）。\nPath 标识 Path 标识指定了主机下的哪些路径可以接受 Cookie（该 URL 路径必须存在于请求 URL 中）。以字符 %x2F (\u0026quot;/\u0026quot;) 作为路径分隔符，子路径也会被匹配。例如，设置 Path=/docs，则以下地址都会匹配：\n /docs /docs/Web/ /docs/Web/HTTP  限制访问 Secure 属性 标记为 Secure 的 Cookie 只应通过被 HTTPS 协议加密过的请求发送给服务端，因此可以预防中间人的攻击。但即便设置了 Secure 标记，敏感信息也不应该通过 Cookie 传输，因为 Cookie 有其固有的不安全性，Secure 标记也无法提供确实的安全保障, 例如，可以访问客户端硬盘的人可以读取它。\nHttpOnly 属性 标记为 HttpOnly 的 Cookie 不能被 JavaScript 脚本调用。跨站脚本攻击 (XSS) 常常使用 JavaScript 的 document.cookie API 窃取用户的 Cookie 信息，因此使用 HttpOnly 标记可以在一定程度上避免 XSS 攻击。\n示例：\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure; HttpOnly 以下为一个Golang实现的简单的使用 Cookie 的代码示例：\n Session  Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束\n Cookie 和 Session 的不同  作用范围不同，Cookie 保存在客户端，Session 保存在服务端 存取方式的不同，Cookie 只能保存 ASCII，Session 可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效 隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取；Session 存储在服务端，安全性相对要好一些 存储大小不同， 单个 Cookie 保存的数据不能超过 4KB，Session 可存储上限远高于 Cookie  七、Web 缓存  Web缓存（Web cache）（或 HTTP 缓存（HTTP cache））是用于临时存储（缓存）Web文档（如HTML页面和图像），以减少服务器延迟的一种信息技术。Web缓存系统会保存下通过这套系统的文档的副本；如果满足某些条件，则可以由缓存满足后续请求。 Web缓存系统既可以指设备，也可以指计算机程序\n 缓存的种类 缓存的种类有很多,其大致可归为两类：私有与共享缓存。共享缓存存储的响应能够被多个用户使用。私有缓存只能用于单独用户。\n 缓存的种类 \n（私有）浏览器缓存 私有缓存（local cache/private cache） 只能用于单独用户。浏览器缓存拥有用户通过 HTTP 下载的所有文件，可以避免再次向服务器发起多余的请求，也可以提供缓存内容的离线浏览。\n（共享）代理缓存 共享缓存（shared cache/proxy cache） 可以被多个用户使用。例如，ISP 或者公司可能会架设一个 web 代理来作为本地网络基础的一部分提供给用户，这样热门的资源就会被重复使用，减少网络拥堵与延迟。\n缓存控制 Cache-Control HTTP/1.1定义的 Cache-Control 头用来区分对缓存机制的支持情况， 请求头和响应头都支持这个属性。通过它提供的不同的值来定义缓存策略。\n禁止进行缓存 缓存中不得存储任何关于客户端请求和服务端响应的内容。每次由客户端发起的请求都会下载完整的响应内容。\nCache-Control: no-store 强制确认缓存 缓存服务器需要先向源服务器验证缓存资源的有效性，只有当缓存资源有效时才能使用该缓存对客户端的请求进行响应。\nCache-Control: no-cache 私有缓存和公共缓存 private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中。\nCache-Control: private public 指令规定了将资源作为公共缓存，可以被任何中间人（比如中间代理、CDN等）缓存，可以被多个用户使用，一般存储在代理服务器中。\nCache-Control: public 过期 max-age 指令出现在请求报文，并且缓存资源的缓存时间小于该指令指定的时间，那么就能接受该缓存，\nmax-age 指令出现在响应报文，表示缓存资源在缓存服务器中保存的时间：\nCache-Control: max-age=31536000 Expires 首部字段也可以用于告知缓存服务器该资源什么时候会过期：\nExpires: Wed, 04 Jul 2012 08:26:05 GMT 在HTTP/1.1中，会优先处理 max-age 指令，在HTTP/1.0中，会忽略掉 max-age 指令。\n验证方式 当使用了 must-revalidate 指令，那就意味着缓存在考虑使用一个陈旧的资源时，必须先验证它的状态，已过期的缓存将不被使用。\nCache-Control: must-revalidate 新鲜度(freshness)  服务端和客户端为资源约定一个过期时间，在该过期时间之前，该资源（缓存副本）就是新鲜的，当过了过期时间后，该资源（缓存副本）则变为陈旧的。驱逐算法用于将陈旧的资源（缓存副本）替换为新鲜的，注意，一个陈旧的资源（缓存副本）是不会直接被清除或忽略的\n 对于含有特定头信息的请求，会去计算缓存寿命。比如Cache-control: max-age=N的头，相应的缓存的寿命就是N。\n缓存失效时间计算公式如下： $$ expirationTime = responseTime + freshnessLifetime - currentAge $$ 其中，responseTime 表示浏览器接收到此响应的时间点。\n缓存验证(validation) ETag  ETag 响应头是 URL 的Entity Tag，作为一个URL资源的标识符，作为缓存的一种强校验器\n ETag: \u0026#34;82e22293907ce725faf67773957acd12\u0026#34; 当服务端返回资源时，可以根据返回内容计算一个 hash 值或者就是一个数字版本号作为 ETag 的值放到响应首部中，客户端可以在后续的请求的头中可以将缓存资源的 ETag 值放到 If-None-Match 头首部，服务器收到该请求后，判断缓存资源的 ETag 值和资源的最新 ETag 值是否一致，如果一致则表示缓存资源有效，返回 304 Not Modified。\nIf-None-Match: \u0026#34;82e22293907ce725faf67773957acd12\u0026#34; Last-Modified Last-Modified 响应头可以作为缓存验证的一种弱校验器，如果响应头里含有这个信息，客户端可以在后续的请求中带上 If-Modified-Since 来验证缓存。服务器只在所请求的资源在给定的日期时间之后对内容进行过修改的情况下才会将资源返回，状态码为 200 OK。如果请求的资源从那时起未经修改，那么返回一个不带有实体主体的 304 Not Modified 响应报文。\nLast-Modified: Wed, 21 Oct 2015 07:28:00 GMT If-Modified-Since: Wed, 21 Oct 2015 07:28:00 GMT Etag 与 Last-Modified的对比 Etag 是强校验器，Last-Modified 是弱校验器，都同时出现时，Etag的优先级更高。Last-Modified的精度只能到秒，如果一个资源频繁修改，用Last-Modified并不能区分，而Etag 由于每次资源更新时都会生成新的值，会使缓存验证更加准确，缺点是频繁生成的策略可能会额外消耗服务器资源。\n强制缓存与协商缓存  强制缓存：浏览器不会向服务器发送任何请求，直接从本地缓存中读取文件并返回状态码200 OK；\n协商缓存：浏览器向服务器发送请求，服务器会根据这个请求的请求首部来判断是否命中协商缓存，如果命中，则返回304 Not Modified并带上新的响应首部通知浏览器从缓存中读取资源\n 强制缓存的首部字段  Expires Cache Control  协商缓存的首部字段   Etag \u0026amp; If-None-Match\n  Last-Modifed \u0026amp; If-Modified-Since\n  强制缓存和协商缓存都存在的情况下，先判断强制缓存是否生效，如果生效，不用发起请求，直接用缓存。如果强制缓存不生效再发起请求判断协商缓存。\n八、HTTP/1.x 的性能问题及优化方案 虽然HTTP/1.1 的持久连接和管道机制允许复用TCP连接，在一个TCP连接中，也可以同时发送多个请求，但是所有的数据通信都是按次序完成的，服务器只有处理完一个回应，才会处理下一个回应。\n比如客户端需要A、B两个资源，管道机制允许浏览器同时发出 A 请求和 B 请求，但服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求，这样如果前面的回应特别慢，后面就会有很多请求排队等着，这称为队头阻塞（Head-of-line blocking）。\n并发连接 HTTP/1.x 可以通过对同一个域名发起多个长连接的方式提高通信效率，此种方式称为并发连接（concurrent connections）。\n但是如果客户端滥用并发连接会对带宽和服务器都产生影响，一般来说，现在的浏览器支持的并发连接个数为6 ~ 8个。\n域名分片 域名分片（domain sharding） 会将内容拆分到多个子域名中。当使用多个域名来处理多个资源时，浏览器能够同时下载更多资源，从而缩短了页面加载时间并改善了用户体验。\n这种方式的问题在于每个域都需要额外的 DNS 查找成本以及建立每个 TCP 连接的开销。\nHTTP/2 HTTP/2 主要是为了改进 HTTP/1.x 的性能问题而产生的，在现在，不推荐使用域名分片的手段提高 HTTP 连接性能，而是直接升级到 HTTP/2。\n九、HTTPS HTTP 的安全性问题  使用明文进行通信，内容可能会被窃听 不验证通信方的身份，通信方的身份有可能遭遇伪装 无法证明报文的完整性，报文有可能遭篡改  HTTPS 概念  超文本传输安全协议（英语：HyperText Transfer Protocol Secure，缩写 HTTPS；常称为 HTTP over TLS、HTTP over SSL 或HTTP Secure），是一种通过计算机网络进行安全通信的协议。\nHTTPS 经由 HTTP 进行通信，但利用 SSL/TLS 来加密数据包。\n严格来说，HTTPS 并不是单独的协议，而是对工作在一加密连接（TLS 或 SSL）上的常规HTTP协议的称呼。\n HTTPS 作用 加密（Confidentiality） 访问者的连接被加密，隐藏了 URL、cookie 和其他敏感的元数据\n认证（Authenticity） 确认访问者正在访问真实网站，而不是与冒充者或通过中间人通信\n完整性保护（Integrity） 访问者与网站之间发送的数据未被篡改或修改\n加密方式 HTTPS 采用混合加密机制\n 使用非对称密钥加密方式，传输对称密钥加密方式所需要的 Secret Key，从而保证安全性 获取到 Secret Key 后，再使用对称密钥加密方式进行通信，从而保证效率  对称密钥加密  对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥\n 非对称密钥加密  非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥\n 参考资料  【日】户根勤. (2017). 网络是怎样连接的. 人民邮电出版社. Kurose, J. F., \u0026amp; Ross, K. W. (2018). 计算机网络-自顶而下方法 (7th ed.). 机械工业出版社. Wikipedia : HTTP MDN : HTTP MDN : Cookies MDN : HTTP Caching Introduction to HTTPS  ","date":"2020-06-12T12:22:57+08:00","permalink":"https://huangkai1008.github.io/p/http/","title":"HTTP"},{"content":"MySQL的日志系统 一、日志类型  MySQL主要有两种日志类型，一种是物理日志（记录在某个数据页上做了什么修改)，一种是逻辑日志(存储了逻辑SQL修改语句)。\nredo log属于物理日志，binlog和undo log属于逻辑日志，其中物理日志的恢复速度远快于逻辑日志。\n 二、重做日志(redo log) 基本概念  重做日志（redo log）是 InnoDB 引擎层的日志，用来记录事务操作引起数据的变化，记录的是数据页的物理修改，提供前滚操作。MySQL 通过 redo log 保证事务的持久性。\n 重做日志由两部分组成，一是内存中的重做日志缓冲区 (redo log buffer)，它是易失的，另一个就是在磁盘上的重做日志文件 (redo log file)，它是持久的。\nInnoDB 引擎对数据更新，是先将更新记录写入到重做日志，在系统空闲时或者按照设定的更新策略再将日志中的内容更新到磁盘中，这就是预写式技术 (Write Ahead logging, WAL)，这种技术可以大大减少IO操作的频率，提升数据刷新的效率。\n逻辑结构 redo log 的大小是固定的，为了能够持续不断的对更新记录进行写入，在redo log日志中设置了两个标志位置，checkpoint和write pos。checkpoint表示记录擦除的位置，write pos表示记录写入的位置。当write pos标志到了日志结尾时，会从结尾跳至日志头部循环写入，所以redo log的逻辑结构并不是线性的，可以看做一个圆周运动，逻辑结构见下图：\n redo log的逻辑结构 \n当write_pos追上checkpoint时，表示redo log日志已经写满。这时不能继续执行新的数据库更新语句，需要停下来先删除一些记录，执行checkpoint规则腾出可写空间。\n checkpoint规则：checkpoint触发后，将buffer中脏数据页和脏日志页都刷到磁盘。所谓的脏数据页就是指内存中未刷到磁盘的数据\n 刷盘  redo log buffer 数据页写入磁盘中的redo log file的过程叫做刷盘。\n 在计算机操作系统中，用户空间(user space)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间(kernel space)的缓冲区(OS Buffer)。因此，redo log buffer写入redo log file实际上是先写入OS Buffer，然后再通过系统调用fsync()将其刷到redo log file中，流程如下图：\n \n当数据修改时，除了修改buffer pool中的数据，还会在redo log中记录这次操作。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复，从而保证了事务的持久性，使得数据库获得crash-safe能力。\n刷盘策略 在提交事务的时候，InnoDB会根据配置的策略来将 redo log 刷盘，这个可以通过innodb_flush_log_at_trx_commit 参数来配置。\nSHOWVARIABLESLIKE\u0026#39;innodb_flush_log_at_trx_commit\u0026#39;;+--------------------------------+-------+|Variable_name|Value|+--------------------------------+-------+|innodb_flush_log_at_trx_commit|1|+--------------------------------+-------+1rowinset(0.00sec)各参数的含义如下表：\n   参数值 含义     0（延迟写） 事务提交时不会将redo log buffer中日志写入到OS Buffer，而是定时写入OS buffer并调用fsync()写入到redo log file中。当系统崩溃，会丢失数据。   1 （实时写，实时刷） 事务每次提交都会将redo log buffer中的日志写入OS buffer并调用fsync()刷到redo log file中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。   2 （实时写，延时刷） 每次提交都仅写入到OS buffer，然后是每秒调用fsync()将os buffer中的日志写入到redo log file。    为了保证事务的持久性，一般使用默认值，将 innodb_flush_log_at_trx_commit 设置为1即可。\n三、二进制日志 (binlog) 基本概念  binlog（二进制日志、归档日志），用于记录数据库执行的写入性操作信息，以二进制的形式保存在磁盘中。\n 使用场景  主从复制：从库利用主库上的 binlog 进行重播，实现主从同步 数据恢复：用于数据库的基于时间点、位点等的还原操作（mysqlbinlog）  日志格式 binlog日志有三种格式，分别为STATMENT、ROW和MIXED。\n 在 MySQL 5.7.7之前，默认的格式是STATEMENT，MySQL 5.7.7之后，默认值是ROW。日志格式通过binlog-format指定。\n STATEMENT STATMENT 基于SQL语句的复制(statement-based replication, SBR)，会记录每一条修改数据的SQL语句和执行语句的上下文信息\n优点 STATMENT 模式不需要记录每一行的变化，减少了binlog的日志量，节省了I/O和存储资源,，从而提高了性能\n缺点 STATMENT 模式在某些情况下会导致主从数据不一致，比如执行sysdate()、sleep()等\nROW ROW 基于行的复制(row-based replication, RBR)，会记录每一行数据被修改的形式\n优点 ROW 模式下的日志内容会非常清楚的记录下每一行数据的修改细节，非常容易理解，而且不会出现某些特定情况下的存储过程和 function，以及 trigger 的调用和触发无法被正确复制问题\n缺点 ROW 模式下会产生大量的日志\nMIXED MIXED 基于STATMENT和ROW两种模式的混合复制(mixed-based replication, MBR)，一般的复制使用STATEMENT模式保存，对于STATEMENT模式无法复制的操作使用ROW模式保存\n刷盘策略 MySQL 只有在事务提交的时候才会记录 binlog 日志，此时日志还在内存中，MySQL 通过sync_binlog参数控制 biglog 的刷盘时机，取值范围是0-N：\n  0： 不做强制要求，由系统自行判断何时写入磁盘\n  1：每次事务提交时 binlog 都会写入磁盘\n  N：每N个事务 binlog 会写入磁盘\n  sync_binlog最安全的是设置是1，这也是 MySQL 5.7.7之后版本的默认值，但是也可以设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。\n与重做日志的区别     redo log binlog     实现方式 InnoDB引擎特有的 MySQL的Server层实现的，所有引擎都可以使用   日志类型 物理日志 逻辑日志   写入方式 循环写，空间固定会用完 追加写入，binlog文件写到一定大小后会切换到下一个   适用场景 崩溃恢复(crash-safe) 主从复制和数据恢复    两阶段提交（Two-phase Commit，2PC） MySQL 事务提交的时候，需要同时完成 redo log 和 binlog 的提交，为了让两份日志之间的逻辑一致，需要用到两阶段提交，这个场景下的两阶段提交发生在 MySQL 内部，和分布式系统的两阶段提交是两个概念。\n \n四、回滚日志 (undo log)  当事务对数据库进行修改，InnoDB引擎不仅会记录redo log，还会生成对应的undo log日志；如果事务执行失败或调用了rollback，导致事务需要回滚，就可以利用undo log中的信息将数据回滚到修改之前的状态。MySQL 通过 undo log 保证事务的原子性。undo log有两个作用，一是提供回滚，二是实现 MVCC\n 回滚日志并不能将数据库物理地恢复到执行语句或者事务之前的样子；它是逻辑日志，当回滚日志被使用时，它只会按照日志逻辑地将数据库中的修改撤销掉，可以理解为，我们在事务中使用的每一条 INSERT 都对应了一条 DELETE，每一条 UPDATE 也都对应一条相反的 UPDATE 语句。\n事务日志 在数据库系统中，事务的原子性和持久性是由事务日志（transaction log）保证的，而redo log和undo log都属于InnoDB引擎层下的事务日志（transaction log）。这两种事务日志可以保证：\n 发生错误或者需要回滚的事务能够成功回滚（原子性） 在事务提交后，数据没来得及写入磁盘就宕机时，在下次重新启动后能够成功恢复数据（持久性）  在数据库中，这两种日志经常都是一起工作的，可以将它们整体看做一条事务日志，其中包含了事务的 ID、修改的行元素以及修改前后的值。\n \n一条事务日志同时包含了修改前后的值，能够非常简单的进行回滚和重做两种操作。\n","date":"2020-06-05T22:07:21+08:00","permalink":"https://huangkai1008.github.io/p/mysql%E7%9A%84%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/","title":"MySQL的日志系统"},{"content":"一、概念  事务就是一组原子性的SQL查询，或者说一个独立的工作单元。如果数据库引擎能够成功地对数据库应用该组查询的全部语句，那么就执行该组查询。如果其中有任何一条语句因为崩溃或其他原因无法执行，那么所有的语句都不会执行。也就是说，事务内的语句，要么全部执行成功，要么全部执行失败。在 MySQL 中，事务支持是在引擎层实现的。\n 隔离级别（Isolation level）   READ UNCOMMITTED（读未提交）\n事务中的修改，即使没有提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也被称为脏读（Dirty Read）。\n  READ COMMITTED（读提交）\nOracle和SQL Server的默认隔离级别。一个事务可以读取另一个已提交的事务。换句话说，一个事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的。这个级别有时候也叫做不可重复读（nonrepeatable read），因为两次执行同样的查询，可能会得到不一样的结果。MySQL的InnoDB引擎在提交读级别通过MVCC解决了不可重复读的问题。\n  REPEATABLE READ（可重复读）\nMySQL的默认隔离级别。一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。MySQL的InnoDB引擎在可重复读级别通过间隙锁解决了幻读问题。\n  SERIALIZABLE（可串行化）\nSERIALIZABLE是最高的隔离级别。它通过强制事务串行执行，避免了前面说的幻读的问题。简单来说，SERIALIZABLE会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用的问题。实际应用中也很少用到这个隔离级别，只有在非常需要确保数据的一致性而且可以接受没有并发的情况下，才考虑采用该级别。\n     隔离级别 脏读可能性 不可重复读可能性 幻读可能性 加锁读     READ UNCOMMITTED √ √ √ ×   READ COMMITTED × √ √ ×   REPEATABLE READ × × √ ×   SERIALIZABLE × × × √     查看MySQL的隔离级别\n SHOWVARIABLESLIKE\u0026#39;transaction_isolation\u0026#39;;+-----------------------+-----------------+|Variable_name|Value|+-----------------------+-----------------+|transaction_isolation|REPEATABLE-READ|+-----------------------+-----------------+1rowinset,1warning(0.00sec) 设置当前会话的隔离级别\n SETSESSIONTRANSACTIONISOLATIONLEVELREADCOMMITTED;# 设置当前会话为RC级别，下个事务生效 事务类型 隐式事务 DML操作的语句都会隐式的开启事务，并且在语句执行后没有错误的话隐式提交。可以通过将MySQL的autocommit这个变量（默认为1）设置为0将事务的隐式提交关闭，但需要注意，DML语句的隐式事务仍会启动，只是区别在于需要手动COMMIT显式提交这个事务，也就是将隐式事务转化为长事务了。\nSHOWVARIABLESLIKE\u0026#39;autocommit\u0026#39;;# 查看隐式事务提交方式 +---------------+-------+|Variable_name|Value|+---------------+-------+|autocommit|ON|+---------------+-------+1rowinset,1warning(0.00sec)显式事务 # 1.显式开启一个事务 STARTTRANSACTION;BEGIN;# 2.提交事务 COMMIT;# 3.回滚事务 ROLLBACK;# 4.在事务中创建保存点，可以在同一事务中创建多个，以便通过ROLLBACK更灵活的回滚 SAVEPOINT;显式开启一个事务时，如果还有未提交的事务会自动提交，并且autocommit会被禁用直到该事务结束。对于显式事务，存在completion_type这样一个变量控制显式事务的行为。有下列三种情况：\n 值为0时即为默认，执行COMMIT后提交该显式事务并结束该事务。 值为1时，执行COMMIT后除了有值为0时的默认行为外，随后会自动开始一个相同隔离级别的事务。术语为COMMIT AND CHAIN 值为2时，执行COMMIT后除了有值为0时的默认行为外，随后会断开与服务器的连接。术语为COMMIT AND RELEASE  二、事务ACID特性 持久性（Durability)  已被提交的事务对数据库的修改应该永久保存在数据库中\n 一个实现了ACID的数据库，相比没有实现ACID的数据库，通常会需要更强的CPU处理能力、更大的内存和更多的磁盘空间。\n原子性（Atomicity）  事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行\n 想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，而在 MySQL 中，恢复机制是通过四、回滚日志 undo log实现的\n一致性（Consistency）  事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。\n数据库对于 ACID 中的一致性的定义是这样的：如果一个事务原子地在一个一致地数据库中独立运行，那么在它执行之后，数据库的状态一定是一致的。对于这个概念，它的第一层意思就是对于数据完整性的约束，包括主键约束、引用约束以及一些约束检查等等，在事务的执行的前后以及过程中不会违背对数据完整性的约束，所有对数据库写入的操作都应该是合法的，并不能产生不合法的数据状态。\n 隔离性（Isolation）  通常来说，一个事务所做的修改在最终提交以前，对其他事务是不可见的。\n ","date":"2020-06-02T22:25:20+08:00","permalink":"https://huangkai1008.github.io/p/mysql%E7%9A%84%E4%BA%8B%E5%8A%A1/","title":"MySQL的事务"},{"content":"MySQL的基础架构 逻辑架构 MySQL可以大体分为Server层和存储引擎层两部分, 见图1\n 图1 Mysql逻辑架构图 \n Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎  连接器(Connector) 连接器负责和客户端建立连接、获取权限、维持和管理连接。\n# Mysql连接命令 mysql-h$ip-P$port-u$user-pMySQL 客户端和服务端完成TCP握手后，连接器需要认证身份\n  如果用户名或密码不对，就会收到一个 Access denied for user 的错误，然后客户端程序结束执行。\n  如果用户名密码认证通过，连接器会到权限表里面查出拥有的权限，之后这个连接里面的权限判断逻辑，都将依赖于此时读到的权限，这就意味着，一个用户成功建立连接后，即使这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n   长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n 连接方式  TCP/IP 命名管道和共享内存 UNIX 域套接字  查询缓存(Query Cache) 在连接建立完成后，MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n 注：MySQL 8.0 版本的查询缓存功能被移除了\n 分析器(Parser) 分析器的主要功能是对SQL语句做解析\n 分析器会先做词法分析，再做语法分析，语法分析器会根据语法规则，判断 SQL 语句是否满足 MySQL 语法  优化器(Query Optimizer) 优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。优化器并不关心表使用的是什么存储引擎，但存储引擎对于优化查询是有影响的。优化器会请求存储引擎提供容量或某个具体操作的开销信息，以及表数据的统计信息等。例如，某些存储引擎的某种索引，可能对一些特定的查询有优化。\n执行器(Query execution engine) 开始执行的时候，要先判断一下对于表有没有执行操作的权限，如果没有，就会返回没有权限的错误。如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。\n对于一个特定的例子\nselect*fromuserwhereID=10;假定ID字段没有索引，那么执行器的执行流程是这样的：\n 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。  ","date":"2020-06-01T21:56:20+08:00","image":"https://blog-1259169620.cos.ap-guangzhou.myqcloud.com/img/mysql-architecture.png","permalink":"https://huangkai1008.github.io/p/mysql%E7%9A%84%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/","title":"MySQL的基础架构"},{"content":"IDE  Jetbrains系列  Editor  Vscode Sublime text Typora(markdown编辑) Notion(笔记软件)  画图  Microsoft visio drawing.io  数据库 Mysql系列  Navicat Tableplus Jetbrains Datagrip  Redis系列  RDM(redis desktop manager)  CVS  Jetbrains系IDE自带 SourceTree  接口测试  Postman  Vm  VirtualBox Vagrant Windows SubLinux(WSL) Vmware  ssh工具  MobaXterm xshell  系统工具  Everything Utools  接口文档工具  apidoc swagger yapi  终端  cmder Windows Termial  ","date":"2019-12-01T22:21:57+08:00","permalink":"https://huangkai1008.github.io/p/awesome-software/","title":"Awesome Software"},{"content":"Loguru是一个好用的第三方python日志库\n安装 pip install loguru 初步使用 添加日志到标准输出流 import sys from loguru import logger logger.add(sys.stderr, format=\u0026#39;{time}{level}{message}\u0026#39;, filter=\u0026#39;my module\u0026#39;, level=\u0026#39;INFO\u0026#39;) 添加日志到文件 from loguru import logger logger.add(\u0026#39;file_1.log\u0026#39;, rotation=\u0026#39;500 MB\u0026#39;) # Automatically rotate too big file logger.add(\u0026#34;file_2.log\u0026#34;, rotation=\u0026#39;12:00\u0026#39;) # New file is created each day at noon logger.add(\u0026#34;file_3.log\u0026#34;, rotation=\u0026#34;1 week\u0026#34;) # Once the file is too old, it\u0026#39;s rotated logger.add(\u0026#34;file_X.log\u0026#34;, retention=\u0026#34;10 days\u0026#34;) # Cleanup after some time logger.add(\u0026#34;file_Y.log\u0026#34;, compression=\u0026#34;zip\u0026#34;) # Save some loved space 捕获异常 from loguru import logger @logger.catch def my_function(x, y, z): # An error? It\u0026#39;s caught anyway! return 1 / (x + y + z) 为日志添加颜色 import sys from loguru import logger logger.add(sys.stdout, colorize=True, format=\u0026#34;\u0026lt;green\u0026gt;{time}\u0026lt;/green\u0026gt; \u0026lt;level\u0026gt;{message}\u0026lt;/level\u0026gt;\u0026#34;) 异步、线程安全、多进程安全 from loguru import logger logger.add(\u0026#34;file.log\u0026#34;, enqueue=True) 完全描述异常  记录代码中发生的异常对于跟踪错误很重要，但是如果您不知道为什么失败，则记录日志就毫无用处。 Loguru通过允许显示整个堆栈跟踪（包括变量值）来帮助您发现问题\n from loguru import logger logger.add(\u0026#34;output.log\u0026#34;, backtrace=True, diagnose=True) # Set \u0026#39;False\u0026#39; to not leak sensitive data in prod 配置到flask import logging import sys from pathlib import Path from flask import Flask from loguru import logger app = Flask(__name__) class InterceptHandler(logging.Handler): def emit(self, record): logger_opt = logger.opt(depth=6, exception=record.exc_info) logger_opt.log(record.levelname, record.getMessage()) def configure_logging(flask_app: Flask): \u0026#34;\u0026#34;\u0026#34;配置日志\u0026#34;\u0026#34;\u0026#34; path = Path(flask_app.config[\u0026#39;LOG_PATH\u0026#39;]) if not path.exists(): path.mkdir(parents=True) log_name = Path(path, \u0026#39;sips.log\u0026#39;) logging.basicConfig(handlers=[InterceptHandler(level=\u0026#39;INFO\u0026#39;)], level=\u0026#39;INFO\u0026#39;) logger.configure(handlers=[{\u0026#34;sink\u0026#34;: sys.stderr, \u0026#34;level\u0026#34;: \u0026#39;INFO\u0026#39;}]) # 配置日志到标准输出流 logger.add( log_name, rotation=\u0026#34;500 MB\u0026#34;, encoding=\u0026#39;utf-8\u0026#39;, colorize=False, level=\u0026#39;INFO\u0026#39; ) # 配置日志到输出到文件 ","date":"2019-11-22T15:19:35+08:00","permalink":"https://huangkai1008.github.io/p/%E6%97%A5%E5%BF%97%E5%BA%93loguru%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/","title":"日志库Loguru使用教程"},{"content":"Evenlet是一个Python的基于携程的网络库，它改变了你代码运行的方式，但是没有改变你怎么写代码\n安装 pip install eventlet 简单使用 从eventlet.green导入相关库 import eventlet from eventlet.green import urllib2 urls = [ \u0026#34;https://www.google.com/intl/en_ALL/images/logo.gif\u0026#34;, \u0026#34;http://python.org/images/python-logo.gif\u0026#34;, \u0026#34;http://us.i1.yimg.com/us.yimg.com/i/ww/beta/y3.gif\u0026#34;, ] def fetch(url): print(\u0026#34;opening\u0026#34;, url) body = urllib2.urlopen(url).read() print(\u0026#34;done with\u0026#34;, url) return url, body pool = eventlet.GreenPool(200) for url, body in pool.imap(fetch, urls): print(\u0026#34;got body from\u0026#34;, url, \u0026#34;of length\u0026#34;, len(body)) 使用spawn使用协程 import time import eventlet def green_thread_1(num): eventlet.greenthread.sleep(1) print(f\u0026#39;green_thread_1 get result {num}\u0026#39;) return x def green_thread_2(num): eventlet.greenthread.sleep(2) print(f\u0026#39;green_thread_2 get result {num}\u0026#39;) return y time1 = time.perf_counter() x = eventlet.spawn(green_thread_1, 1) y = eventlet.spawn(green_thread_2, 2) x.wait() y.wait() time2 = time.perf_counter() print(time2 - time1) \u0026gt;\u0026gt;\u0026gt; green_thread_1 get result 1 green_thread_2 get result 2 2.0049271  spawn函数产生的协程可以通过wait函数来执行并获取返回结果， 如上例子中， 使用绿色线程的休眠模拟io操作的耗时, 程序就会切换到下一个协程，切换协程由调度器决定\n 使用monkey-patch from eventlet import monkey_patch from eventlet import GreenPool green_pool = GreenPool() monkey_patch() def producer(): pass def consumer(): pass green_pool.spawn(producer) green_pool.spawn(consumer) green_pool.waitall() 和gunicorn一起使用 以flask应用为例\ngunicorn --worker-class eventlet -b 0.0.0.0:5000 -w 1 run:app ","date":"2019-11-22T11:20:20+08:00","permalink":"https://huangkai1008.github.io/p/eventlet%E4%BD%BF%E7%94%A8/","title":"Eventlet使用"},{"content":"GitFlow 基本介绍 Gitflow 提倡使用 feature branches 模式来开发各个相互独立的功能，同时分成不同的分支以便进行集成和发布\n Git Workflow \n分支介绍   长期分支\n   主分支(master)\n  开发分支(develop)\n   在gitflow下, develop 分支是一个类似全能的分支，用来存放、测试所有的代码，同时也是主要是用来合并代码、集成功能的分支\n作为一个开发人员，在这是不允许直接提交代码到 develop 分支上的，更更更不允许直接提交到 master 分支。master 分支代表的是一个「stable」的分支，包含的是已投产或即将投产的代码。如果一段代码在 master 分支上，即代表它已经投产或即将投产发布\n  短期分支\n   功能分支(feature)\n  热补丁分支(hotfix)\n  预发分支(release)\n     feature\n功能性分支从 develop 分支上产生， 根据新需求来新建 feature 分支， 开发完成后，要再并入 develop 分支， 合并完分支后一般会删除这个feature分支\n在 feature 分支的命名规则上，可以约定以 「feat-」开头，后面跟上问题单编号。如「feat-APS-151-add-name-field」。以「feat-」开头，可以让 CI 服务器识别出这是一个 feature 分支，「APS-151」是Jira 问题单的编号，可以链接到问题单，剩下的部分则是对该功能的简短的说明\n  release\nrelease分支基于develop创建\n打完release分支之后，我们可以在这个release分支上测试，修改bug等。同时，其它开发人员可以基于develop分支新建feature (记住：一旦打了release分支之后不要从develop分支上合并新的改动到release分支)发布release分支时，合并release到master和develop， 同时在master分支上打个tag记住release版本号，然后可以删除release分支了。它的命名，可以采用release-*的形式\n在测试中，难免发现 bug，我们可以直接在 release 分支上修改，修改完后再 merge 到 develop 分支上（develop 分支包含的是已发布或者即将发布的代码）\n  hotfix\n这个分支是负责在生产环境上发现的问题，如 bug 或者性能问题等。 hotfixes 分支和 release 分支类似，都以 release 版本号命名，唯一的区别就是 hotfixes 是新建于 master 分支，release 分支则是从 develop 分支而来，修补结束以后，再合并进Master和Develop分支。它的命名，可以采用hotfix-*的形式\n    ​\n","date":"2019-10-12T14:36:49+08:00","permalink":"https://huangkai1008.github.io/p/git%E5%B7%A5%E4%BD%9C%E6%B5%81/","title":"Git工作流"},{"content":"Black是一个毫不妥协的python代码格式化工具, 特点是可配置项较少 Black依赖于python3.6+, 官方地址在https://github.com/psf/black\nInstall pip install black Configure   pyproject.toml\n[tool.black] skip-string-normalization = true # 禁用双引号风格   pycharm\n  Create external tools\n windows: File -\u0026gt; Settings -\u0026gt; Tools -\u0026gt; External Tools\n  External Tools \n  Configure file watcher\n File Watcher \n    ","date":"2019-09-27T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/black%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","title":"Black安装和使用"},{"content":"安装   custom installer\ncurl -sSL https://raw.githubusercontent.com/sdispater/poetry/master/get-poetry.py | python source $HOME/.poetry/env   pip\npip install poetry # 不推荐, 可能会有冲突   验证安装\npoetry --version 使用   项目初始化\n  从pipenv/pip等工具迁移\npoetry init # 进入交互式命令行填写项目信息, 会生成pyproject.toml    添加依赖\n  添加包\npoetry add poetry add fastapi=0.38.1 -E all # pipenv install fastapi[all] poetry add celery --extras \u0026#34;librabbitmq redis auth msgpack\u0026#34; # pip install \u0026#34;celery[librabbitmq,redis,auth,msgpack]\u0026#34;   依赖安装\npoetry install # 会从pyproject.toml文件里读取, 如果有poetry.lock文件则会从lock文件中读取锁定依赖并安装   虚拟环境地址\n windows10: $User\\AppData\\Local\\pypoetry\\Cache\\virtualenvs      配置   添加源\n修改pyproject.toml\n[[tool.poetry.source]] name = \u0026#34;tsinghua\u0026#34; url = \u0026#34;https://pypi.tuna.tsinghua.edu.cn/simple/\u0026#34; verify_ssl = true   完整的实例 [tool.poetry] name = \u0026#34;market-admin\u0026#34; version = \u0026#34;0.1.0\u0026#34; description = \u0026#34;market-admin is a Market background management system with fastapi\u0026#34; authors = [\u0026#34;huangkai\u0026#34;] license = \u0026#34;MIT\u0026#34; [tool.poetry.dependencies] python = \u0026#34;^3.7\u0026#34; fastapi = {version = \u0026#34;0.38.1\u0026#34;, extras = [\u0026#34;all\u0026#34;]} python-dotenv = \u0026#34;0.10.2\u0026#34; tortoise-orm = \u0026#34;0.13.5\u0026#34; aiomysql = \u0026#34;0.0.20\u0026#34; loguru = \u0026#34;^0.3.2\u0026#34; [tool.poetry.dev-dependencies] pytest = \u0026#34;6.2.1\u0026#34; coverage = \u0026#34;5.3.1\u0026#34; [tool.black]\t# Black工具配置 target-version = [\u0026#39;py37\u0026#39;] skip-string-normalization = true [[tool.poetry.source]]\t# 源配置 name = \u0026#34;tsinghua\u0026#34; url = \u0026#34;https://pypi.tuna.tsinghua.edu.cn/simple/\u0026#34; default = true [build-system] requires = [\u0026#34;poetry\u0026gt;=0.12\u0026#34;] build-backend = \u0026#34;poetry.masonry.api\u0026#34; ","date":"2019-09-14T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/poetry%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","title":"Poetry安装和使用"},{"content":"Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。Nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的，第一个公开版本0.1.0发布于2004年10月4日。 其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。2011年6月1日，nginx 1.0.4发布。 Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，在BSD-like 协议下发行。其特点是占有内存少，并发能力强\nInstall   platform: Centos7\n  version: 7.2\n  安装\nwget http://nginx.org/download/nginx-1.16.1.tar.gz tar -zxvf nginx-1.16.1.tar.gz cd nginx-1.16.1 sudo ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install whereis nginx # 查看nginx安装地址 /usr/local/nginx   BasicUse   启动\n/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf   重启\ncd /usr/local/nginx/sbin ./nginx -s reload   Example Conf # /usr/local/nginx/conf/nginx.conf  #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info;  #pid logs/nginx.pid;  events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;  # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;  # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;  #access_log logs/access.log main;  sendfile on; #tcp_nopush on;  #keepalive_timeout 0;  keepalive_timeout 65; #gzip on;  # 包含aps的nginx配置  include /usr/local/nginx/conf/aps/*.conf; server { listen 80; server_name localhost; #charset koi8-r;  #access_log logs/host.access.log main;  location / { root html; index index.html index.htm; } #error_page 404 /404.html;  # redirect server error pages to the static page /50x.html  #  error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80  #  #location ~ \\.php$ {  # proxy_pass http://127.0.0.1;  #}  # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000  #  #location ~ \\.php$ {  # root html;  # fastcgi_pass 127.0.0.1:9000;  # fastcgi_index index.php;  # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name;  # include fastcgi_params;  #}  # deny access to .htaccess files, if Apache\u0026#39;s document root  # concurs with nginx\u0026#39;s one  #  #location ~ /\\.ht {  # deny all;  #}  } # another virtual host using mix of IP-, name-, and port-based configuration  #  #server {  # listen 8000;  # listen somename:8080;  # server_name somename alias another.alias;  # location / {  # root html;  # index index.html index.htm;  # }  #}  # HTTPS server  #  #server {  # listen 443 ssl;  # server_name localhost;  # ssl_certificate cert.pem;  # ssl_certificate_key cert.key;  # ssl_session_cache shared:SSL:1m;  # ssl_session_timeout 5m;  # ssl_ciphers HIGH:!aNULL:!MD5;  # ssl_prefer_server_ciphers on;  # location / {  # root html;  # index index.html index.htm;  # }  #} } # /usr/local/nginx/conf/aps/aps.conf server { listen 10050; server_name localhost; # 访问后端api  location /api/ { proxy_pass http://127.0.0.1:5500/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } # 访问静态文件  location /static/ { alias /usr/local/nginx/html/aps/dist/; # 静态文件访问硬盘  } # 访问主页  location / { root /usr/local/nginx/html/aps/dist/; index index.html index.htm; } } ","date":"2019-08-26T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/nginx%E5%AE%89%E8%A3%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","title":"Nginx安装和基本使用"},{"content":"基本安装  使用rufus以dd模式写入U盘 从u盘启动 将manjaro启动项中的driver和boot添加或修改driver=intel才能进入安装界面(双显卡笔记本) 安装系统, 注意不要联网, 否则容易卡在安装 reboot进入系统 manjaro启动项中quiet后增加nouveau.modeset=0(双显卡)  双显卡使用prime管理连接外接显示器   删除bumblebee或者开源驱动\nsudo mhwd -r pci nonfree 0300   安装nvidia私有闭源驱动\n  方法一:\nsudo mhwd -i pci video-nvidia 或\nsudo mhwd -i pci video-nvidia-390xx # 390xx或者435xx, 数字是驱动版本...   方法二 系统设置-硬件设定中右键安装video-nvidia-390xx之类的驱动\n    安装依赖\nsudo pacman -S linuxXXX-headers acpi_call-dkms xorg-xrandr xf86-video-intel git  注: XXX 为内核版本， 本来我的5.3有点问题，降级成4.19才可以，以4.19为例便是 linux419-headers\n   注入\nsudo modprobe acpi_call   使用github上的脚本\ncd ~ # 建议在用户目录下操作 git clone https://github.com/dglt1/optimus-switch-sddm.git cd optimus-switch-sddm chmod +x install.sh sudo ./install.sh   reboot\n  ","date":"2019-08-01T22:21:57+08:00","permalink":"https://huangkai1008.github.io/p/manjaro%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Manjaro安装配置"},{"content":"Git提交代码时需要提交Message, 为了使得提交信息更清晰明了, 需要确定规范\n现在比较流行的规范是Angular规范, 也根据此规范衍生了Conventional Commits specification\n规范 格式  \u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; \u0026lt;BLANK LINE\u0026gt; \u0026lt;body\u0026gt; \u0026lt;BLANK LINE\u0026gt; \u0026lt;footer\u0026gt; 按照空行分割为三个部分, 分别为Header，Body 和 Footer 其中，Header 是必需的，Body 和 Footer 可以省略 不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）, 这是为了避免自动换行影响美观\n组成 Header Header部分只有一行，包括三个字段：type（必需）、scope（可选）和subject（必需）\n  type\n​type用于说明 commit 的类别，只允许使用下面7个标识\n  feat：新功能（feature） fix：修补bug docs：文档（documentation） style： 格式（不影响代码运行的变动） refactor：重构（即不是新增功能，也不是修改bug的代码变动） test：增加测试 chore：构建过程或辅助工具的变动   如果type为feat和fix，则该 commit 将肯定出现在 Change log 之中。其他情况（docs、chore、style、refactor、test）由你决定，要不要放入 Change log，建议是不要\n  scope\nscope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同\n  subject\nsubject是 commit 目的的简短描述，不超过50个字符\n  以动词开头，使用第一人称现在时，比如change，而不是changed或changes 第一个字母小写 结尾不加句号     Body Body 部分是对本次 commit 的详细描述，可以分成多行\n 使用第一人称现在时，比如使用change而不是changed或changes\n  应该说明代码变动的动机，以及与以前行为的对比\n Footer Footer部分可以用于表达不兼容变动和关闭Issue\n  不兼容变动\n如果当前代码与上一个版本不兼容，则 Footer 部分以BREAKING CHANGE开头，后面是对变动的描述、以及变动理由和迁移方法\n  关闭Issue\n Closes APS-151\n   Jetbrains工具配置   git commit template\n 提交信息模板\n   Gitmoji\n 添加emoji表情在commit信息中\n   ","date":"2019-07-12T14:14:15+08:00","permalink":"https://huangkai1008.github.io/p/git-commit-message%E7%BC%96%E5%86%99%E8%A7%84%E8%8C%83/","title":"Git Commit Message编写规范"},{"content":"Web Frameworks  Uvicorn 基于asyncio开发的一个轻量级高效的 web 服务器框架 Starlette Quart Responder Fastapi Sanic  Utils  Poetry 新的Python依赖包管理工具 Pipenv 用了很久的现在也在用的\u0026hellip; 有时候Locking速度感人, pipfile声明版本可以防止很多坑 Black 代码格式化库 Loguru python日志库 PySnooper python Debugger  ORM  Gino tortoise-orm  Test  locust 压力测试工具  Environment  python-dotenv environs  ","date":"2019-05-27T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/%E5%80%BC%E5%BE%97%E5%85%B3%E6%B3%A8%E7%9A%84python%E5%BA%93/","title":"值得关注的Python库"},{"content":"使用IDEA初始化Spring Boot项目   选择File -\u0026gt; New -\u0026gt; Project 新建项目\n  选择Spring Initializr， 点击Next，填写项目基本信息  \n  项目依赖勾选Spring Web选择Finish等待项目构建\n \n  ​\n","date":"2019-02-07T11:15:10+08:00","permalink":"https://huangkai1008.github.io/p/spring%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B7%A5%E5%85%B7/","title":"Spring初始化工具"},{"content":"RabbitMQ  Platform: Centos7  安装   install Erlang\nyum install erlang   install rabbitMQ\n# rpm安装 wget https://github.com/rabbitmq/rabbitmq-server/releases/download/rabbitmq_v3_6_14/rabbitmq-server-3.6.14-1.el7.noarch.rpm yum install rabbitmq-server-3.6.14-1.el7.noarch.rpm # yum安装 yum install rabbitmq-server   配置   启动远程访问\n[{rabbit, [ {loopback_users, []} ]}]   安装插件\n/sbin/rabbitmq-plugins enable rabbitmq_management   使用   服务命令\nsystemctl start rabbitmq-server.service # 启动 systemctl status rabbitmq-server.service\t# 查看状态 systemctl restart rabbitmq-server.service\t# 重启 systemctl enable rabbitmq-server.service # 开机自启   添加用户\nrabbitmqctl add_user root root123 # 添加新用户，用户名为 \u0026#34;root\u0026#34; ，密码为 \u0026#34;root123\u0026#34; rabbitmqctl set_permissions -p / root \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; # 为root用户添加所有权限 rabbitmqctl set_user_tags root administrator # 设置root 用户为管理员角色   访问web页面\nhttp://ip:15672   ","date":"2018-11-12T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/rabbitmq%E5%9F%BA%E7%A1%80%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/","title":"RabbitMQ基础安装使用"},{"content":"mysql中min和max查询优化  max()函数需扫描where条件过滤后的所有行\n  慎用max()函数，特别是频繁执行的sql，若需用到可转化为order by id desc limit 1\n ","date":"2018-11-06T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/mysql%E4%BC%98%E5%8C%96/","title":"Mysql优化"},{"content":"Redis 安装   Platform: centos7\n  version: 5.0\n  安装\nwget http://download.redis.io/releases/redis-5.0.0.tar.gz # 获取包 tar -zxvf redis-5.0.0.tar.gz mv redis-5.0.0 /usr/local/redis make \u0026amp;\u0026amp; make install   Redis配置   设置配置文件目录\nmkdir -p /etc/redis cp redis.conf /etc/redis   修改配置文件\nvim /etc/redis/redis.conf daemonize yes (no -\u0026gt; yes) # 守护进程 bind 0.0.0.0 (127.0.0.1 -\u0026gt; 0.0.0.0) # 远程登录 protected-mode no (yes -\u0026gt; no) # 关闭保护模式/或者添加密码   Redis使用   启动\n/usr/local/bin/redis-server /etc/redis/redis.conf   查看启动\nps -ef | grep redis   客户端使用\nredis-cli # 进入 127.0.0.1:6379\u0026gt;set name Huang Ok redis-cli shutdown # 关闭客户端   开机启动配置\n# 开机启动要配置在 rc.local 中，而 /etc/profile 文件，要有用户登录了，才会被执行。 echo \u0026#34;/usr/local/bin/redis-server /etc/redis/redis.conf \u0026amp;\u0026#34; \u0026gt;\u0026gt; /etc/rc.local   Supervisor管理Redis   更改redis配置\nvim /etc/redis/redis.conf daemonize no (yes -\u0026gt; no) # 取消守护进程   创建supervisor对redis的配置文件\nvim /etc/supervisord.d/redis.ini  `redis.ini`文件如下  [program:redis] command=redis-server /etc/redis/redis.conf\t#\t启动Redis的命令 autostart=true\t#\tsupervisord启动时，该程序也启动 autorestart=true # 异常退出时，自动启动 startsecs=3\t# 启动后持续3s后未发生异常，才表示启动成功\t stdout_logfile=/var/log/supervisor/redis/redis.log # 标准输出流日志 stderr_logfile=/var/log/supervisor/redis/redis_err.log\t# 标准错误输出流日志   ","date":"2018-10-11T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/redis%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Redis安装配置"},{"content":"安装Angular 确保node/npm已安装 node -v 查看node版本 npm -v 查看npm版本 安装typescript npm install -g typescript 安装Angular CLI npm install -g @angular/cli ng version # 验证angular-cli版本 建立一个新的Angular项目 Angular CLI 为我们提供了两种方式，用于创建新的应用程序：\n  ng init - 在当前目录创建新的应用程序\n  ng new - 创建新的目录，然后在新建的目录中运行 ng init 命令\n因此 ng new 与 ng init 的功能是相似的，只是 ng new 会为我们创建新的目录\n  创建应用 ng new my-app 可用选项  --dry-run: boolean, 默认为 false, 若设置 dry-run 则不会创建任何文件 --verbose: boolean, 默认为 false --link-cli: boolean, 默认为 false, 自动链接到 @angular/cli 包 --skip-install: boolean, 默认为 false, 表示跳过 npm install --skip-git: boolean, 默认为 false, 表示该目录不初始化为 git 仓库 --skip-tests: boolean, 默认为 false, 表示不创建 tests 相关文件 --skip-commit: boolean, 默认为 false, 表示不进行初始提交 --directory: string, 用于设置创建的目录名，默认与应用程序的同名 --source-dir: string, 默认为 'src', 用于设置源文件目录的名称 --style: string, 默认为 'css', 用于设置选用的样式语法 ('css', 'less' or 'scss') --prefix: string, 默认为 'app', 用于设置创建新组件时，组件选择器使用的前缀 --mobile: boolean, 默认为 false,表示是否生成 Progressive Web App 应用程序 --routing: boolean, 默认为 false, 表示新增带有路由信息的模块，并添加到根模块中 --inline-style: boolean, 默认为 false, 表示当创建新的应用程序时，使用内联样式 --inline-template: boolean, 默认为 false, 表示当创建新的应用程序时，使用内联模板  ","date":"2018-10-09T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/angular-starter/","title":"Angular Starter"},{"content":"安装  Platform: centos7  ","date":"2018-09-12T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/mongodb%E7%9A%84%E5%AE%89%E8%A3%85/","title":"MongoDB的安装"},{"content":"MariaDB安装   platform: Centos7\n  Install\nyum install -y mariadb-server   MariaDB配置使用   Using\nsystemctl start mariadb.service # 启动 systemctl enable mariadb.service # 开机自启   Configure\n  首先是设置密码，会提示先输入密码\n Enter current password for root (enter for none): \u0026lt;–直接回车\n  Set root password? [Y/n] \u0026lt;– 是否设置root用户密码，输入y并回车或直接回车\n  New password: \u0026lt;– 设置root用户的密码\n  Re-enter new password: \u0026lt;– 再输入一次你设置的密码\n  其他配置\n  Remove anonymous users? [Y/n] \u0026lt;– 是否删除匿名用户，Y回车\n  Disallow root login remotely? [Y/n] \u0026lt;–是否禁止root远程登录, N回车,\n  Remove test database and access to it? [Y/n] \u0026lt;– 是否删除test数据库，Y回车\n  Reload privilege tables now? [Y/n] \u0026lt;– 是否重新加载权限表，Y回车2.开启远程访问\n   开启远程访问\n  GRANTALLPRIVILEGESON*.*TO\u0026#39;root\u0026#39;@\u0026#39;%\u0026#39;IDENTIFIEDBY\u0026#39;123456\u0026#39;WITHGRANTOPTION; 刷新权限  flushprivileges 配置文件地址     ","date":"2018-09-09T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/mariadb%E5%AE%89%E8%A3%85/","title":"MariaDB安装"},{"content":"Mysql安装  版本: 8.0 添加源 yum local install https://repo.mysql.com//mysql80-community-release-el7-1.noarch.rpm  安装 yum install mysql-community-server   Mysql配置   初始化\nsudo mysqld --initialize --user=mysql --basedir=/usr --datadir=/var/lib/mysql   启动mysql\nsystemctl start mysqld   设置mysql开机自启\nsystemctl enable mysqld   查看初始密码\ngrep \u0026#39;temporary password\u0026#39; /var/log/mysqld.log   进入mysql\nmysql -u root -p   修改密码\nALTERUSER\u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39;IDENTIFIEDBY\u0026#39;Huang|12345\u0026#39;  查看版本\nselectversion();+-----------+|version()|+-----------+|8.0.16|+-----------+1rowinset(0.00sec)  查看端口\nshowglobalvariableslike\u0026#39;port\u0026#39;;+---------------+-------+|Variable_name|Value|+---------------+-------+|port|3306|+---------------+-------+1rowinset(0.04sec)  远程访问\nusemysql;updateusersethost=\u0026#39;%\u0026#39;whereuser=\u0026#39;root\u0026#39;;flushprivileges  ","date":"2018-09-09T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/mysql%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","title":"Mysql安装配置"},{"content":"数据库系统的目的(Purpose of Database Systems) 在早期，数据库应用程序直接建立在文件系统之上，导致一系列的问题\n  数据冗余和不一致(Data redundancy and inconsistency)\n  数据访问难度大(Difficulty in accessing data)\n  数据隔离(Data isolation)\n  完整性问题(Integrity problems)\n 完整性约束(Integrity constraints)问题\n难以添加新约束和修改约束\n   原子性更新(Atomicity of updates)\n 更新失败可能会导致数据库的数据处于不一致的状态，或者只更新了部分数据\n例如: 从一方转账给另一方，只会有完成转账和完全没发生转账两种情况，不会出现转账方转账了但是收款方未收到款项的问题\n   多用户并发访问(Concurrent access by multiple users)\n 并发访问需要高性能的支持， 而不受控制的并发访问可能会导致数据不一致\n   安全问题(Security problems)\n 文件系统难以提供安全保障\n 数据库系统就是为了解决这些问题产生的\n  数据模型(Data Models) 组成  一系列用于描述的工具    数据(Data)\n  数据关系(Data relationships)\n 数据语义(Data semantics) 数据约束(Data constraints)     关系模型(Relational model) 实体关系数据模型(Entity-Relationship data model 主要用于数据库设计) 基于对象的数据模型(Object-based data models (Object-oriented and Object-relational)) 半结构化数据模型(Semi-structured data model (XML))  数据视图(View of Data) 一个数据库系统的结构如下图  View of data \n模式与实例(Instances and Schema) 类似于编程语言中的类型和变量\n 逻辑模式(logic schema) 数据库的总体逻辑结构，类似于程序设计中的变量类型信息 物理模式(physical schema) 数据库的总体物理结构 实例(instance) 数据库在特定时间点的实际内容， 类似于变量的值  物理数据独立性(Physical Data Independence)  定义： 在不更改逻辑模式的情况下修改物理模式的能力\n   应用程序依赖于逻辑模式(logic schema)\n  一般来说，不同级别和组件应该定义得很好，以便在某些部分中进行更改，不严重影响他人\n  数据定义语言(Data Definition Language)  定义数据库模式的规范表示法\n createtableinstructor(IDchar(5),namevarchar(20),dept_namevarchar(20),salarynumeric(8,2))DDL编译器生成一组存储表模板信息的数据字典（data dictionary)\n数据字典包含元信息(metadata)\n 数据库模式(database schema) 完整性约束(Integrity constraints)  主键   授权(Authorization)  数据处理语言(Data Manipulation Language )  用于访问和更新由适当数据模型组织的数据的语言（查询语言）\n  DML一般分为两种类型  Pure Commercial  例如SQL      ​\n结构化查询语言(Structured Query Language, SQL)  SQL查询语言是非过程的查询将多个表（可能只有一个）作为输入，并始终返回一个表(SQL query language is nonprocedural. A query takes as input several tables (possibly only one) and always returns a single table)\n 数据库设计(Database Design)   逻辑设计(logic design) \u0026ndash; 决定数据库模式\n  业务决定\n 我们应该在数据库中记录哪些属性\n   计算机科学决定\n  我们应该有什么关系模式     属性应该如何分布在不同的关系模式中       物理设计(physical design) \u0026ndash; 决定数据库的物理布局\n  ","date":"2018-09-09T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA-%E4%BB%8B%E7%BB%8D/","title":"数据库系统概论-介绍"},{"content":"安装   Platform: Centos7\n  version: 1.12\n  安装\ncd /opt wget https://studygolang.com/dl/golang/go1.12.4.linux-amd64.tar.gz tar xzvf go1.12.4.linux-amd64.tar.gz\t# 安装   配置环境变量\nvim ~/.zshrc\t# 如果用bash就是vim ~/.bashrc # 追加golang配置 export GOROOT=/opt/go export PATH=$PATH:$GOROOT/bin # 立即生效 source ~/.zshrc # 查看版本 go version   ","date":"2018-07-31T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/golang%E5%AE%89%E8%A3%85/","title":"Golang安装"},{"content":"Python默认的json模块序列化并不是很全面，只能序列化基本的数据类型, 像一些时间格式或者自定义类型都不能序列化，所以在有些时候需要扩展json模块的json encoder\n扩展 import datetime as dt import decimal import json import enum from collections.abc import Iterator class ExtendedEncoder(json.JSONEncoder): def default(self, o): if isinstance(o, dt.datetime): return o.strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;) elif isinstance(o, dt.date): return o.strftime(\u0026#39;%Y-%m-%d\u0026#39;) elif isinstance(o, decimal.Decimal): return float(o) elif isinstance(o, Iterator): return list(o) elif isinstance(o, enum.Enum): return o.value return json.JSONEncoder.default(self, o) 使用场景   日常格式化\n例如对于日期格式的格式化\nimport datetime as dt now = dt.datetime.now() 对于now如果使用json.dumps(t_now)便会触发TypeError: Object of type datetime is not JSON serializable使用扩展的Encoder\n\u0026gt;\u0026gt;\u0026gt; json.dumps(now, cls=ExtendedEncoder) \u0026#39;2018-04-09 23:04:49\u0026#39;   Flask\n修改flask类的json_encoder\nfrom flask import Flask as _Flask class QuizFlask(_Flask): \u0026#34;\u0026#34;\u0026#34; 自定义flask \u0026#34;\u0026#34;\u0026#34; json_encoder = ExtendedEncoder def make_response(self, rv): if rv is None: rv = dict() if isinstance(rv, Iterator): rv = list(rv) return super(QuizFlask, self).make_response(rv)   Tortoise-orm\n模型jsonfield的encoder\nimport json from tortoise import fields from tortoise.models import Model __all__ = [\u0026#39;OurModel\u0026#39;] class OurModel(Model): \u0026#34;\u0026#34;\u0026#34;示例model\u0026#34;\u0026#34;\u0026#34; id = fields.IntField(pk=True) cat_ids = fields.JSONField( encoder=ExtendedEncoder, decoder=json.decoder ) # JsonField的encoder   ","date":"2018-04-09T22:49:14+08:00","permalink":"https://huangkai1008.github.io/p/%E6%89%A9%E5%B1%95python-json-encoder/","title":"扩展Python Json Encoder"},{"content":"介绍 从Python3.2开始，标准库为我们提供了 concurrent.futures 模块，它提供了 ThreadPoolExecutor (线程池)和ProcessPoolExecutor (进程池)两个类。\n相比 threading 等模块，该模块通过 submit 返回的是一个 future 对象，它是一个未来可期的对象，通过它可以获悉线程的状态主线程(或进程)中可以获取某一个线程(进程)执行的状态或者某一个任务执行的状态及返回值：\n1.主线程可以获取某一个线程（或者任务的）的状态，以及返回值。\n2.当一个线程完成的时候，主线程能够立即知道。\n3.让多线程和多进程的编码接口一致。\n基本使用 from concurrent.futures import ThreadPoolExecutor import time def get_page(url): time.sleep(url) return url with ThreadPoolExecutor(max_workers=5) as t: # 创建一个最大容纳数量为5的线程池 task1 = t.submit(get_page, 1) task2 = t.submit(get_page, 2) # 通过submit提交执行的函数到线程池中 task3 = t.submit(get_page, 3) print(f\u0026#34;task1: {task1.done()}\u0026#34;) # 通过done来判断线程是否完成 print(f\u0026#34;task2: {task2.done()}\u0026#34;) print(f\u0026#34;task3: {task3.done()}\u0026#34;) time.sleep(2.5) print(f\u0026#34;task1: {task1.done()}\u0026#34;) print(f\u0026#34;task2: {task2.done()}\u0026#34;) print(f\u0026#34;task3: {task3.done()}\u0026#34;) print(task1.result()) # 通过result来获取返回值 \u0026gt;\u0026gt;\u0026gt; task1: False task2: False task3: False ... task1: True task2: True task3: False Api as_completed  concurrent.futures.as_completed(fs, timeout=None)\n  返回一个生成器在迭代过程中会阻塞\n  直到线程完成或者异常时,返回一个被set_result的Future对象\n  此方法的返回顺序为哪个线程先失败/完成就返回\n from concurrent.futures import ThreadPoolExecutor, as_completed import time def get_page(url): time.sleep(url) return url with ThreadPoolExecutor(max_workers=5) as t: # 创建一个最大容纳数量为5的线程池 tasks = [t.submit(get_page, page) for page in range(1, 5)] for future in as_completed(tasks): result = future.result() print(result) \u0026gt;\u0026gt;\u0026gt; 1 2 3 4 wait  concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED)\n  fs: 执行的序列\n  timeout: 等待的最大时间，如果超过这个时间即使线程未执行完成也将返回\n  return_when: 表示wait返回结果的条件，默认为 ALL_COMPLETED 全部执行完成再返回\n   FIRST_COMPLETED   函数将在任意可等待对象结束或取消时返回。    FIRST_EXCEPTION   函数将在任意可等待对象因引发异常而结束时返回。 当没有引发任何异常时它就相当于 ALL_COMPLETED。    ALL_COMPLETED   函数将在所有可等待对象结束或取消时返回。  from concurrent.futures import ThreadPoolExecutor, wait import time def get_page(url): time.sleep(url) return url with ThreadPoolExecutor(max_workers=5) as t: # 创建一个最大容纳数量为5的线程池 tasks = [t.submit(get_page, page) for page in range(1, 5)] a, b = wait(tasks) print(a) print(b) \u0026gt;\u0026gt;\u0026gt; {\u0026lt;Future at 0x1c071fb1f28 state=finished returned int\u0026gt;, \u0026lt;Future at 0x1c071fb1d68 state=finished returned int\u0026gt;, \u0026lt;Future at 0x1c071f9fd68 state=finished returned int\u0026gt;, \u0026lt;Future at 0x1c071d78278 state=finished returned int\u0026gt;} set() map  *concurrent.futures.Executor.map(fn, iterables, timeout=None)\n  fn: 第一个参数 fn 是需要线程执行的函数\n  *iterables: 第二个参数接受一个可迭代对象\n  timeout: 第三个参数 timeout 跟 wait() 的 timeout 一样，但由于 map 是返回线程执行的结果，如果 timeout小于线程执行时间会抛异常 TimeoutError\n from concurrent.futures import ThreadPoolExecutor import time def get_page(url): time.sleep(url) return url URLS = [url for url in range(1, 4)] with ThreadPoolExecutor(max_workers=5) as executor: # 创建一个最大容纳数量为5的线程池 for result in executor.map(get_page, URLS): print(result) \u0026gt;\u0026gt;\u0026gt; 1 2 3 回调函数 回调函数(add_done_callback)是在调用线程完成后再调用的\nfrom concurrent.futures import ThreadPoolExecutor, wait import threading import time def get_page(url): time.sleep(url) return url def call_back(worker): print(f\u0026#39;tid: {threading.current_thread().ident}\u0026#39;, worker.result()) with ThreadPoolExecutor() as t: tasks = [] for page in range(1, 5): task = t.submit(get_page, url=page) task.add_done_callback(call_back) tasks.append(task) wait(tasks) \u0026gt;\u0026gt;\u0026gt; tid: 6392 1 tid: 14936 2 tid: 12516 3 tid: 10524 4 异常处理  通过添加回调函数的方法处理异常  import logging def executor_callback(worker): logging.info(f\u0026#39;finished\u0026#39;) worker_exception = worker.exception() if worker_exception: logging.exception(worker_exception) 备注  一定使用with关键字处理线程池，在某些情况下线程池可能不能自动回收线程资源，with可以避免内存持续增长等情况  ","date":"2018-02-08T22:49:14+08:00","permalink":"https://huangkai1008.github.io/p/python%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BD%BF%E7%94%A8/","title":"Python线程池使用"},{"content":"  Platform: centos7\n  version: 5.0\n  安装   Uninstall old versions\nsudo yum remove docker \\  docker-client \\  docker-client-latest \\  docker-common \\  docker-latest \\  docker-latest-logrotate \\  docker-logrotate \\  docker-engine   Install Docker CE\nsudo yum install -y yum-utils \\  device-mapper-persistent-data \\  lvm2 # 设置stable源 sudo yum-config-manager \\  --add-repo \\  https://download.docker.com/linux/centos/docker-ce.repo # 安装Docker CE sudo yum install docker-ce docker-ce-cli containerd.io   启动  Docker启动 sudo systemctl start docker\t# 启动Docker sudo systemctl status docker\t# 查看Docker状态   ","date":"2018-01-31T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/docker%E5%AE%89%E8%A3%85/","title":"Docker安装"},{"content":"  遇到in查询之类的批量删除或者更新，可以使用synchronize_session=False\ndb.session.delete(synchronize_session=False)   使用find_in_set\nfrom sqlalchemy.sql.expression import func db.session.query(Post).filter(func.find_in_set(\u0026#39;10\u0026#39;, Post.c.tag_id))   批量增加删除\ndb.session.add_all(instances) db.session.delete_all(instances)   Mysql IS NULL判断\nisnot() is_()   Mysql 联合主键\nfrom sqlalchemy import PrimaryKeyConstraint class Node(Model): __table_args__ = ( PrimaryKeyConstraint(\u0026#39;pk1\u0026#39;, \u0026#39;pk2\u0026#39;), )   Flask_sqlalchemy支持Double精度类型字段\nfrom sqlalchemy import Column from sqlalchemy.dialects.mysql import DOUBLE from app import db class BaseModel(Model): id = db.Column(db.Integer, primary_key=True) # Flask_sqlalchemy double_column = Column(DOUBLE, comment=\u0026#39;双精度字段\u0026#39;) # Sqlalchemy mysql double column   subquery使用实例\nconditions = list() for key, value in material_period.items(): condition = and_( CraftEntityAttrs.attr_number == key, CraftEntityAttrs.attr_value == value ) conditions.append(condition) if not conditions: return list() stmt = ( db.session.query(CraftEntityAttrs.entity_id, CraftEntityAttrs.cat_number) .filter(or_(*conditions)) .subquery() ) query = db.session.query( CraftEntityPeriodHours.proc_number, CraftEntityPeriodHours.period, CraftEntityPeriodHours.hours, CraftEntityPeriodHours.major_wrapper_skill_level, stmt.c.cat_number, ).filter(CraftEntityPeriodHours.entity_id == stmt.c.entity_id) stmt = ( db.session.query(ProducePlan.row_id, ProducePlan.row_seq) .filter(ProducePlan.proc_number.in_(constants.COIL_PROC_NUMBERS)) .distinct() .subquery() ) query = ( BatchDetail.query.join( stmt, and_( BatchDetail.row_id == stmt.c.row_id, BatchDetail.row_seq == stmt.c.row_seq, ), ) .join(PlanRow, BatchDetail.row_id == PlanRow.id) .join(RowProject, PlanRow.project_id == RowProject.id) .join(Order, RowProject.order_id == Order.id) .with_entities( Order.order_number, Order.id.label(\u0026#39;order_id\u0026#39;), Order.project_name, RowProject.row_project_number, RowProject.id.label(\u0026#39;project_id\u0026#39;), Order.purchase_unit, RowProject.fac_number, RowProject.mat_number, RowProject.mat_desc, PlanRow.com_qty, BatchDetail.row_id, PlanRow.plan_row_number, BatchDetail.batch_id, BatchDetail.batch_number, BatchDetail.batch_qty, BatchDetail.batch_seq, BatchDetail.single_pack_cycle, ) .order_by(RowProject.id, BatchDetail.batch_id, BatchDetail.batch_seq) ) stmt = ( db.session.query(ProducePlan.project_id) .outerjoin( ProducePlanCompletion, ProducePlan.plan_id == ProducePlanCompletion.plan_id ) .filter( or_( ProducePlanCompletion.completion.is_(None), ProducePlanCompletion.completion == constants.ProducePlanCompletion.not_scheduled.value, ) ) .distinct() .subquery() ) query = db.session.query(ProducePlan.project_id).filter( ProduceUserPlan.project_id.in_(stmt), ProduceUserPlan.proc_type == \u0026#39;design\u0026#39; )   ","date":"2017-06-14T13:56:20+08:00","permalink":"https://huangkai1008.github.io/p/sqlalchemy%E4%BD%BF%E7%94%A8%E6%B3%A8%E6%84%8F/","title":"Sqlalchemy使用注意"},{"content":"Python安装   Platform: centos7\n  Version: 3.7\n  安装编译环境\nyum install zlib-devel bzip2-devel openssl-devel ncurses-devel libffi-devel   下载\nwget --no-check-certificate https://www.python.org/ftp/python/3.7.4/Python-3.7.4.tgz   创建安装目录解压\nsudo mkdir /usr/local/python3 tar -zxvf Python-3.7.4.tgz cd Python-3.7.4/   编译安装\nsudo ./configure --prefix=/usr/local/python3 # 指定创建的目录 make \u0026amp;\u0026amp; make install # 编译安装   软链接  创建python和pip软链接 ln -s /usr/local/python3/bin/python3 /usr/bin/python3 # python3 软链接 ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 # pip3软链接 ln -s /usr/local/python3/bin/pipenv /usr/bin/pipenv # pipenv软链接   使用pyenv管理多个Python版本 安装pyenv  安装脚本 curl https://pyenv.run | bash  manjaro sudo pacman -S pyenv   pyenv基本使用  展示可以安装的版本 pyenv install --list  安装python pyenv install 3.7.4  manjaro如遇到ModuleNotFoundError: No module named \u0026lsquo;_ctypes\u0026rsquo;, 可执行sudo pacman -S pkgconf libffi\n  查看可使用的版本，带*表示当前使用的版本 $ pyenv versions * system (set by /home/huangkai/.pyenv/version) 3.7.4  配置及管理python版本  使用pyenv global 配置当前用户的系统使用的python版本 使用pyenv shell 配置当前shell的python版本，退出shell则失效 使用pyenv local 配置所在项目（目录）的python版本    ","date":"2017-01-08T22:49:14+08:00","permalink":"https://huangkai1008.github.io/p/python%E5%AE%89%E8%A3%85/","title":"Python安装"}]